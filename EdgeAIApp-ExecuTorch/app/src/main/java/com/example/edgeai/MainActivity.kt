package com.example.edgeai

import android.Manifest
import android.app.Activity
import android.content.Intent
import android.content.pm.PackageManager
import android.graphics.Bitmap
import android.graphics.BitmapFactory
import android.net.Uri
import android.os.Bundle
import android.os.Environment
import android.provider.MediaStore
import android.util.Log
import android.widget.Button
import android.widget.EditText
import android.widget.ImageView
import android.widget.LinearLayout
import android.widget.RadioButton
import android.widget.RadioGroup
import android.widget.SeekBar
import android.widget.TextView
import android.widget.Toast
import androidx.core.app.ActivityCompat
import androidx.core.content.ContextCompat
import androidx.core.content.FileProvider
import com.example.edgeai.ml.CLIPInference
import com.example.edgeai.ml.LLaMAInference
import kotlinx.coroutines.*
import java.io.File
import java.text.SimpleDateFormat
import java.util.*

/**
 * EdgeAI CLIP Inference Demo
 * Main activity for running CLIP inference on Qualcomm EdgeAI
 */
class MainActivity : Activity() {

    // UI Components
    private lateinit var imageView: ImageView
    private lateinit var resultTextView: TextView
    private lateinit var captureButton: Button
    private lateinit var galleryButton: Button
    private lateinit var inferenceButton: Button
    
    // New UI Components for LLaMA
    private lateinit var modelSelectionGroup: RadioGroup
    private lateinit var clipModelRadio: RadioButton
    private lateinit var llamaModelRadio: RadioButton
    private lateinit var clipImageSection: LinearLayout
    private lateinit var llamaTextSection: LinearLayout
    private lateinit var clipActionButtons: LinearLayout
    private lateinit var llamaActionButtons: LinearLayout
    private lateinit var textInput: EditText
    private lateinit var maxTokensSeekBar: SeekBar
    private lateinit var maxTokensText: TextView
    private lateinit var clearTextButton: Button
    private lateinit var exampleButton: Button

    // ML Components
    private var clipInference: CLIPInference? = null
    private var llamaInference: LLaMAInference? = null
    private var currentBitmap: Bitmap? = null
    private var currentPhotoPath: String = ""
    private var currentModel: String = "CLIP" // "CLIP" or "LLaMA"

    companion object {
        private const val TAG = "EdgeAI_CLIP"
        private const val REQUEST_IMAGE_CAPTURE = 1
        private const val REQUEST_GALLERY_IMAGE = 2
        private const val REQUEST_PERMISSIONS = 3
    }

    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        setContentView(R.layout.activity_main)

        Log.i(TAG, "üöÄ Starting EdgeAI CLIP Demo")

        initializeViews()
        requestPermissions()
        initializeModels()
    }

    /**
     * Initialize UI components and set up click listeners
     */
    private fun initializeViews() {
        try {
            // Basic UI components
            imageView = findViewById(R.id.imageView)
            resultTextView = findViewById(R.id.resultTextView)
            captureButton = findViewById(R.id.captureButton)
            galleryButton = findViewById(R.id.galleryButton)
            inferenceButton = findViewById(R.id.inferenceButton)
            
            // New UI components for model selection
            modelSelectionGroup = findViewById(R.id.modelSelectionGroup)
            clipModelRadio = findViewById(R.id.clipModelRadio)
            llamaModelRadio = findViewById(R.id.llamaModelRadio)
            clipImageSection = findViewById(R.id.clipImageSection)
            llamaTextSection = findViewById(R.id.llamaTextSection)
            clipActionButtons = findViewById(R.id.clipActionButtons)
            llamaActionButtons = findViewById(R.id.llamaActionButtons)
            textInput = findViewById(R.id.textInput)
            maxTokensSeekBar = findViewById(R.id.maxTokensSeekBar)
            maxTokensText = findViewById(R.id.maxTokensText)
            clearTextButton = findViewById(R.id.clearTextButton)
            exampleButton = findViewById(R.id.exampleButton)

            // Set up model selection listener
            modelSelectionGroup.setOnCheckedChangeListener { _, checkedId ->
                when (checkedId) {
                    R.id.clipModelRadio -> switchToCLIPModel()
                    R.id.llamaModelRadio -> switchToLLaMAModel()
                }
            }

            // Set up button click listeners
            captureButton.setOnClickListener {
                Log.i(TAG, "üì∑ Camera button clicked")
                captureImage()
            }
            galleryButton.setOnClickListener {
                Log.i(TAG, "üñºÔ∏è Gallery button clicked")
                selectFromGallery()
            }
            clearTextButton.setOnClickListener {
                Log.i(TAG, "üóëÔ∏è Clear text button clicked")
                textInput.setText("")
            }
            exampleButton.setOnClickListener {
                Log.i(TAG, "üí° Example button clicked")
                loadExamplePrompt()
            }
            inferenceButton.setOnClickListener {
                Log.i(TAG, "üöÄ Inference button clicked")
                runInference()
            }

            // Set up max tokens seekbar
            maxTokensSeekBar.setOnSeekBarChangeListener(object : SeekBar.OnSeekBarChangeListener {
                override fun onProgressChanged(seekBar: SeekBar?, progress: Int, fromUser: Boolean) {
                    maxTokensText.text = "$progress tokens"
                }
                override fun onStartTrackingTouch(seekBar: SeekBar?) {}
                override fun onStopTrackingTouch(seekBar: SeekBar?) {}
            })

            // Initially disable inference until model is loaded
            inferenceButton.isEnabled = false
            resultTextView.text = "üîÑ Initializing models..."

            // Start with CLIP model
            switchToCLIPModel()

            Log.i(TAG, "‚úÖ UI components initialized successfully")

        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Failed to initialize UI: ${e.message}", e)
            Toast.makeText(this, "UI initialization failed", Toast.LENGTH_LONG).show()
        }
    }

    /**
     * Switch to CLIP model UI
     */
    private fun switchToCLIPModel() {
        currentModel = "CLIP"
        clipImageSection.visibility = LinearLayout.VISIBLE
        llamaTextSection.visibility = LinearLayout.GONE
        clipActionButtons.visibility = LinearLayout.VISIBLE
        llamaActionButtons.visibility = LinearLayout.GONE
        inferenceButton.text = "üöÄ Run CLIP Inference"
        Log.i(TAG, "üñºÔ∏è Switched to CLIP model")
    }

    /**
     * Switch to LLaMA model UI
     */
    private fun switchToLLaMAModel() {
        currentModel = "LLaMA"
        clipImageSection.visibility = LinearLayout.GONE
        llamaTextSection.visibility = LinearLayout.VISIBLE
        clipActionButtons.visibility = LinearLayout.GONE
        llamaActionButtons.visibility = LinearLayout.VISIBLE
        inferenceButton.text = "üöÄ Run LLaMA Inference"
        Log.i(TAG, "üìù Switched to LLaMA model")
    }

    /**
     * Load example prompt for LLaMA
     */
    private fun loadExamplePrompt() {
        val examples = listOf(
            "Explain the concept of artificial intelligence in simple terms.",
            "Write a short story about a robot learning to paint.",
            "What are the benefits of renewable energy?",
            "Describe the process of photosynthesis.",
            "How does machine learning work?"
        )
        val randomExample = examples.random()
        textInput.setText(randomExample)
        Log.i(TAG, "üí° Loaded example prompt: ${randomExample.take(50)}...")
    }

    /**
     * Initialize both CLIP and LLaMA models
     */
    private fun initializeModels() {
        CoroutineScope(Dispatchers.IO).launch {
            try {
                Log.i(TAG, "üîß Initializing simplified models...")

                // Initialize CLIP (simplified)
                clipInference = CLIPInference(this@MainActivity)
                val clipSuccess = clipInference?.initialize() ?: false

                // Initialize LLaMA (simplified)
                Log.i(TAG, "üöÄ Creating LLaMAInference instance...")
                llamaInference = LLaMAInference(this@MainActivity)
                Log.i(TAG, "üîß Calling LLaMA initialize()...")
                val llamaSuccess = try {
                    llamaInference?.initialize() ?: false
                } catch (e: Exception) {
                    Log.e(TAG, "‚ùå LLaMA initialization failed: ${e.message}", e)
                    false
                }
                Log.i(TAG, "üìä LLaMA initialization result: $llamaSuccess")

                withContext(Dispatchers.Main) {
                    val status = buildString {
                        append("‚úÖ Models Status:\n")
                        append("CLIP: ${if (clipSuccess) "Ready" else "Failed"}\n")
                        append("LLaMA: ${if (llamaSuccess) "Ready" else "Failed"}\n\n")
                        if (clipSuccess && llamaSuccess) {
                            append("Both models are ready! Select a model and start inference.")
                        } else {
                            append("Some models failed to load. Check logs for details.")
                        }
                    }
                    
                    resultTextView.text = status
                    inferenceButton.isEnabled = clipSuccess || llamaSuccess
                    
                    if (clipSuccess && llamaSuccess) {
                        Toast.makeText(this@MainActivity, "All models loaded successfully!", Toast.LENGTH_SHORT).show()
                    } else {
                        Toast.makeText(this@MainActivity, "Some models failed to load", Toast.LENGTH_LONG).show()
                    }
                }

            } catch (e: Exception) {
                Log.e(TAG, "‚ùå Model initialization error: ${e.message}", e)
                withContext(Dispatchers.Main) {
                    resultTextView.text = "‚ùå Model initialization error: ${e.message}"
                    Toast.makeText(this@MainActivity, "Model initialization failed", Toast.LENGTH_LONG).show()
                }
            }
        }
    }

    /**
     * Initialize CLIP inference engine (legacy method)
     */
    private fun initializeCLIP() {
        CoroutineScope(Dispatchers.IO).launch {
            try {
                Log.i(TAG, "üîß Initializing CLIP inference engine...")

                clipInference = CLIPInference(this@MainActivity)
                val success = clipInference?.initialize() ?: false

                withContext(Dispatchers.Main) {
                    if (success) {
                        resultTextView.text = "‚úÖ CLIP model ready! Select an image to begin inference."
                        Toast.makeText(this@MainActivity, "CLIP model loaded successfully!", Toast.LENGTH_SHORT).show()
                        Log.i(TAG, "‚úÖ CLIP inference engine ready")
                    } else {
                        resultTextView.text = "‚ùå Failed to initialize CLIP model. Check logs for details."
                        Toast.makeText(this@MainActivity, "Failed to load CLIP model", Toast.LENGTH_LONG).show()
                        Log.e(TAG, "‚ùå CLIP initialization failed")
                    }
                }

            } catch (e: Exception) {
                Log.e(TAG, "‚ùå CLIP initialization error: ${e.message}", e)
                withContext(Dispatchers.Main) {
                    resultTextView.text = "‚ùå CLIP initialization error: ${e.message}"
                    Toast.makeText(this@MainActivity, "CLIP initialization failed", Toast.LENGTH_LONG).show()
                }
            }
        }
    }

    /**
     * Request necessary permissions for camera and storage
     */
    private fun requestPermissions() {
        val permissions = arrayOf(
            Manifest.permission.CAMERA,
            Manifest.permission.WRITE_EXTERNAL_STORAGE,
            Manifest.permission.READ_EXTERNAL_STORAGE
        )

        val permissionsNeeded = permissions.filter {
            ContextCompat.checkSelfPermission(this, it) != PackageManager.PERMISSION_GRANTED
        }

        if (permissionsNeeded.isNotEmpty()) {
            Log.i(TAG, "üîê Requesting permissions: ${permissionsNeeded.joinToString()}")
            ActivityCompat.requestPermissions(this, permissionsNeeded.toTypedArray(), REQUEST_PERMISSIONS)
        } else {
            Log.i(TAG, "‚úÖ All permissions already granted")
        }
    }

    /**
     * Launch camera to capture image
     */
    private fun captureImage() {
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA) != PackageManager.PERMISSION_GRANTED) {
            Toast.makeText(this, "Camera permission required", Toast.LENGTH_SHORT).show()
            return
        }

        try {
            val intent = Intent(MediaStore.ACTION_IMAGE_CAPTURE)
            val photoFile = createImageFile()
            val photoURI = FileProvider.getUriForFile(this, "${packageName}.fileprovider", photoFile)

            intent.putExtra(MediaStore.EXTRA_OUTPUT, photoURI)
            startActivityForResult(intent, REQUEST_IMAGE_CAPTURE)

            Log.i(TAG, "üì∑ Camera intent launched, saving to: $currentPhotoPath")

        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Error launching camera: ${e.message}", e)
            Toast.makeText(this, "Error launching camera: ${e.message}", Toast.LENGTH_SHORT).show()
        }
    }

    /**
     * Open gallery to select image
     */
    private fun selectFromGallery() {
        try {
            val intent = Intent(Intent.ACTION_PICK, MediaStore.Images.Media.EXTERNAL_CONTENT_URI)
            startActivityForResult(intent, REQUEST_GALLERY_IMAGE)
            Log.i(TAG, "üñºÔ∏è Gallery selection launched")
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Error opening gallery: ${e.message}", e)
            Toast.makeText(this, "Error opening gallery", Toast.LENGTH_SHORT).show()
        }
    }

    /**
     * Create temporary file for camera capture
     */
    private fun createImageFile(): File {
        val timeStamp = SimpleDateFormat("yyyyMMdd_HHmmss", Locale.getDefault()).format(Date())
        val storageDir = getExternalFilesDir(Environment.DIRECTORY_PICTURES)

        return File.createTempFile("CLIP_${timeStamp}_", ".jpg", storageDir).apply {
            currentPhotoPath = absolutePath
        }
    }

    /**
     * Handle results from camera or gallery
     */
    override fun onActivityResult(requestCode: Int, resultCode: Int, data: Intent?) {
        super.onActivityResult(requestCode, resultCode, data)

        if (resultCode == Activity.RESULT_OK) {
            when (requestCode) {
                REQUEST_IMAGE_CAPTURE -> {
                    Log.i(TAG, "üì∑ Image captured, loading from: $currentPhotoPath")
                    currentBitmap = BitmapFactory.decodeFile(currentPhotoPath)
                    displayImage(currentBitmap, "Camera")
                }

                REQUEST_GALLERY_IMAGE -> {
                    data?.data?.let { uri ->
                        Log.i(TAG, "üñºÔ∏è Image selected from gallery: $uri")
                        currentBitmap = loadImageFromUri(uri)
                        displayImage(currentBitmap, "Gallery")
                    } ?: Log.w(TAG, "‚ö†Ô∏è No image data received from gallery")
                }
            }
        } else {
            Log.w(TAG, "‚ö†Ô∏è Activity result not OK: requestCode=$requestCode, resultCode=$resultCode")
        }
    }

    /**
     * Load image from URI
     */
    private fun loadImageFromUri(uri: Uri): Bitmap? {
        return try {
            val inputStream = contentResolver.openInputStream(uri)
            val bitmap = BitmapFactory.decodeStream(inputStream)
            inputStream?.close()
            Log.i(TAG, "‚úÖ Image loaded successfully: ${bitmap?.width}x${bitmap?.height}")
            bitmap
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Error loading image from URI: ${e.message}", e)
            Toast.makeText(this, "Error loading selected image", Toast.LENGTH_SHORT).show()
            null
        }
    }

    /**
     * Display loaded image and enable inference
     */
    private fun displayImage(bitmap: Bitmap?, source: String) {
        bitmap?.let {
            imageView.setImageBitmap(it)
            inferenceButton.isEnabled = (clipInference != null)
            resultTextView.text = "‚úÖ Image loaded from $source (${it.width}x${it.height}). Ready for CLIP inference!"
            Log.i(TAG, "‚úÖ Image displayed, inference button enabled: ${inferenceButton.isEnabled}")
        } ?: run {
            Log.e(TAG, "‚ùå Failed to display image - bitmap is null")
            Toast.makeText(this, "Failed to load image", Toast.LENGTH_SHORT).show()
        }
    }

    /**
     * Run inference based on selected model
     */
    private fun runInference() {
        when (currentModel) {
            "CLIP" -> runCLIPInference()
            "LLaMA" -> runLLaMAInference()
            else -> {
                Toast.makeText(this, "No model selected", Toast.LENGTH_SHORT).show()
            }
        }
    }

    /**
     * Run CLIP inference on current image
     */
    private fun runCLIPInference() {
        val bitmap = currentBitmap
        if (bitmap == null) {
            Toast.makeText(this, "Please select an image first", Toast.LENGTH_SHORT).show()
            return
        }

        if (clipInference == null) {
            Toast.makeText(this, "CLIP model not initialized", Toast.LENGTH_SHORT).show()
            return
        }

        // Disable button during inference
        inferenceButton.isEnabled = false
        resultTextView.text = "üîÑ Running CLIP inference on ${bitmap.width}x${bitmap.height} image..."

        Log.i(TAG, "üöÄ Starting CLIP inference...")

        CoroutineScope(Dispatchers.IO).launch {
            try {
                val startTime = System.currentTimeMillis()

                // Run inference
                val results = clipInference?.runInference(bitmap)

                val inferenceTime = System.currentTimeMillis() - startTime
                Log.i(TAG, "‚úÖ CLIP inference completed in ${inferenceTime}ms")

                // Format and display results
                val formattedResults = formatCLIPResults(results, inferenceTime)
                saveResults(formattedResults)

                withContext(Dispatchers.Main) {
                    resultTextView.text = formattedResults
                    inferenceButton.isEnabled = true
                    Toast.makeText(this@MainActivity, "‚úÖ CLIP inference completed in ${inferenceTime}ms!", Toast.LENGTH_SHORT).show()
                }

            } catch (e: Exception) {
                Log.e(TAG, "‚ùå CLIP inference failed: ${e.message}", e)
                withContext(Dispatchers.Main) {
                    resultTextView.text = "‚ùå CLIP inference failed: ${e.message}\n\nCheck logs for more details."
                    inferenceButton.isEnabled = true
                    Toast.makeText(this@MainActivity, "CLIP inference failed", Toast.LENGTH_SHORT).show()
                }
            }
        }
    }

    /**
     * Run LLaMA inference on input text
     */
    private fun runLLaMAInference() {
        val inputText = textInput.text.toString().trim()
        if (inputText.isEmpty()) {
            Toast.makeText(this, "Please enter some text first", Toast.LENGTH_SHORT).show()
            return
        }

        if (llamaInference == null) {
            Toast.makeText(this, "LLaMA model not initialized", Toast.LENGTH_SHORT).show()
            return
        }

        val maxTokens = maxTokensSeekBar.progress

        // Disable button during inference
        inferenceButton.isEnabled = false
        resultTextView.text = "üîÑ Running LLaMA inference on text: ${inputText.take(50)}..."

        Log.i(TAG, "üöÄ Starting LLaMA inference...")

        CoroutineScope(Dispatchers.IO).launch {
            try {
                val startTime = System.currentTimeMillis()

                // Run inference
                val result = llamaInference?.runInference(inputText)

                val inferenceTime = System.currentTimeMillis() - startTime
                Log.i(TAG, "‚úÖ LLaMA inference completed in ${inferenceTime}ms")

                // Format and display results
                val formattedResults = formatLLaMAResults(result, inputText, maxTokens, inferenceTime)
                saveResults(formattedResults)

                withContext(Dispatchers.Main) {
                    resultTextView.text = formattedResults
                    inferenceButton.isEnabled = true
                    Toast.makeText(this@MainActivity, "‚úÖ LLaMA inference completed in ${inferenceTime}ms!", Toast.LENGTH_SHORT).show()
                }

            } catch (e: Exception) {
                Log.e(TAG, "‚ùå LLaMA inference failed: ${e.message}", e)
                withContext(Dispatchers.Main) {
                    resultTextView.text = "‚ùå LLaMA inference failed: ${e.message}\n\nCheck logs for more details."
                    inferenceButton.isEnabled = true
                    Toast.makeText(this@MainActivity, "LLaMA inference failed", Toast.LENGTH_SHORT).show()
                }
            }
        }
    }

    /**
     * Format CLIP inference results for display
     */
    private fun formatCLIPResults(results: Map<String, FloatArray>?, inferenceTime: Long): String {
        if (results.isNullOrEmpty()) {
            return "‚ùå No inference results received\n\nPossible issues:\n- Model not loaded properly\n- QNN runtime error\n- Input preprocessing error"
        }

        val builder = StringBuilder()
        builder.append("üéØ CLIP Inference Results\n")
        builder.append("=" .repeat(40) + "\n")
        builder.append("‚è±Ô∏è Inference Time: ${inferenceTime}ms\n")
        builder.append("üìÖ Timestamp: ${SimpleDateFormat("yyyy-MM-dd HH:mm:ss", Locale.getDefault()).format(Date())}\n")
        builder.append("üñºÔ∏è Input Image: ${currentBitmap?.width}x${currentBitmap?.height}\n\n")

        results.forEach { (outputName, data) ->
            builder.append("üîç Output Tensor: $outputName\n")
            builder.append("üìè Size: ${data.size} elements\n")

            if (data.isNotEmpty()) {
                val max = data.maxOrNull() ?: 0f
                val min = data.minOrNull() ?: 0f
                val mean = data.average().toFloat()
                val std = kotlin.math.sqrt(data.map { (it - mean) * (it - mean) }.average()).toFloat()

                builder.append("üìä Statistics:\n")
                builder.append("   Max:  ${"%.6f".format(max)}\n")
                builder.append("   Min:  ${"%.6f".format(min)}\n")
                builder.append("   Mean: ${"%.6f".format(mean)}\n")
                builder.append("   Std:  ${"%.6f".format(std)}\n")

                // Show sample values
                builder.append("üî¢ Sample Values:\n")
                val sampleCount = minOf(10, data.size)
                for (i in 0 until sampleCount) {
                    builder.append("   [$i]: ${"%.6f".format(data[i])}\n")
                }

                if (data.size > 10) {
                    builder.append("   ... (${data.size - 10} more values)\n")
                }
            } else {
                builder.append("‚ö†Ô∏è Empty output tensor\n")
            }

            builder.append("\n")
        }

        builder.append("üíæ Results saved to external storage\n")
        builder.append("üì± Device: ${android.os.Build.MODEL} (${android.os.Build.DEVICE})\n")

        return builder.toString()
    }

    /**
     * Format LLaMA inference results for display
     */
    private fun formatLLaMAResults(result: String?, inputText: String, maxTokens: Int, inferenceTime: Long): String {
        if (result.isNullOrEmpty()) {
            return "‚ùå No LLaMA inference result received\n\nPossible issues:\n- Model not loaded properly\n- QNN runtime error\n- Input processing error"
        }

        val builder = StringBuilder()
        builder.append("üéØ LLaMA Inference Results\n")
        builder.append("=" .repeat(40) + "\n")
        builder.append("‚è±Ô∏è Inference Time: ${inferenceTime}ms\n")
        builder.append("üìÖ Timestamp: ${SimpleDateFormat("yyyy-MM-dd HH:mm:ss", Locale.getDefault()).format(Date())}\n")
        builder.append("üìù Input Text: ${inputText.take(100)}${if (inputText.length > 100) "..." else ""}\n")
        builder.append("üî¢ Max Tokens: $maxTokens\n")
        builder.append("üìè Generated Length: ${result.length} characters\n\n")

        builder.append("ü§ñ Generated Response:\n")
        builder.append("-".repeat(40) + "\n")
        builder.append(result)
        builder.append("\n" + "-".repeat(40) + "\n\n")

        builder.append("üíæ Results saved to external storage\n")
        builder.append("üì± Device: ${android.os.Build.MODEL} (${android.os.Build.DEVICE})\n")

        return builder.toString()
    }

    /**
     * Save results to external storage
     */
    private fun saveResults(results: String) {
        try {
            val timestamp = SimpleDateFormat("yyyyMMdd_HHmmss", Locale.getDefault()).format(Date())
            val filename = "edgeai_clip_results_$timestamp.txt"
            val documentsDir = getExternalFilesDir(Environment.DIRECTORY_DOCUMENTS)
            val file = File(documentsDir, filename)

            file.writeText(results)

            Log.i(TAG, "üíæ Results saved to: ${file.absolutePath}")

            // Also save a copy in app's internal files for easy access
            val internalFile = File(filesDir, "latest_clip_results.txt")
            internalFile.writeText(results)

        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Failed to save results: ${e.message}", e)
        }
    }

    /**
     * Handle permission request results
     */
    override fun onRequestPermissionsResult(requestCode: Int, permissions: Array<out String>, grantResults: IntArray) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults)

        if (requestCode == REQUEST_PERMISSIONS) {
            val deniedPermissions = permissions.filterIndexed { index, _ ->
                grantResults[index] != PackageManager.PERMISSION_GRANTED
            }

            if (deniedPermissions.isEmpty()) {
                Log.i(TAG, "‚úÖ All permissions granted")
                Toast.makeText(this, "All permissions granted", Toast.LENGTH_SHORT).show()
            } else {
                Log.w(TAG, "‚ö†Ô∏è Denied permissions: ${deniedPermissions.joinToString()}")
                Toast.makeText(this, "Some permissions denied. App functionality may be limited.", Toast.LENGTH_LONG).show()
            }
        }
    }

    /**
     * Clean up resources
     */
    override fun onDestroy() {
        super.onDestroy()
        Log.i(TAG, "üßπ Cleaning up resources...")

        try {
            clipInference?.release()
            clipInference = null
            llamaInference?.release()
            llamaInference = null
            currentBitmap?.recycle()
            currentBitmap = null
        } catch (e: Exception) {
            Log.e(TAG, "‚ùå Error during cleanup: ${e.message}", e)
        }

        Log.i(TAG, "‚úÖ MainActivity destroyed")
    }

    override fun onPause() {
        super.onPause()
        Log.i(TAG, "‚è∏Ô∏è Activity paused")
    }

    override fun onResume() {
        super.onResume()
        Log.i(TAG, "‚ñ∂Ô∏è Activity resumed")
    }
}