# Example YAML configuration file for training experiments
# Reduced model sizes to stay under 50M parameters
# Note: n_layers is automatically determined from the length of n_head_layerlist

- n_embd: 512
  block_size: 256
  n_head_layerlist: [8, 8, 4, 4]
  mlp_size_layerlist: [1024, 1024, 512, 512]
  # n_layers: 4, ~15M params

- n_embd: 768
  block_size: 256
  n_head_layerlist: [12, 8, 6]
  mlp_size_layerlist: [2048, 1536, 1024]
  # n_layers: 3, ~25M params

- n_embd: 640
  block_size: 256
  n_head_layerlist: [8, 8, 8, 8]
  mlp_size_layerlist: [1280, 1280, 1280, 1280]
  # n_layers: 4, ~30M params

- n_embd: 512
  block_size: 256
  n_head_layerlist: [8, 4, 8, 4, 8, 4]
  mlp_size_layerlist: [1024, 512, 1024, 512, 1024, 512]
  # n_layers: 6, ~20M params

- n_embd: 896
  block_size: 256
  n_head_layerlist: [14, 7, 14]
  mlp_size_layerlist: [2688, 1344, 2688]
  # n_layers: 3, ~40M params

- n_embd: 384
  block_size: 256
  n_head_layerlist: [6, 6, 6, 6, 6, 6]
  mlp_size_layerlist: [768, 768, 768, 768, 768, 768]
  # n_layers: 6, ~12M params

- n_embd: 448
  block_size: 256
  n_head_layerlist: [7, 7, 7, 7, 7]
  mlp_size_layerlist: [896, 896, 896, 896, 896]
  # n_layers: 5, ~18M params

- n_embd: 320
  block_size: 256
  n_head_layerlist: [8, 4, 8, 4, 8, 4, 8, 4]
  mlp_size_layerlist: [640, 320, 640, 320, 640, 320, 640, 320]
  # n_layers: 8, ~10M params

- n_embd: 576
  block_size: 256
  n_head_layerlist: [9, 6, 9, 6]
  mlp_size_layerlist: [1152, 576, 1152, 576]
  # n_layers: 4, ~22M params

- n_embd: 704
  block_size: 256
  n_head_layerlist: [11, 11, 11]
  mlp_size_layerlist: [2112, 1408, 2112]
  # n_layers: 3, ~35M params