{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klei22/nanoGPT/blob/csv_process_flow/NanoGPT_Quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "## **CPU Quickstart**\n",
        "\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this section for a CPU Quickstart for training from scratch plus inference."
      ],
      "metadata": {
        "id": "pn59dT_cokXS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM-6qXrqoknT"
      },
      "source": [
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "### **Install CPU Dependencies**\n",
        "\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "1eb072cd-14dd-45f1-aac5-a20b5dde01bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.3\n",
            "    Uninstalling MarkupSafe-2.1.3:\n",
            "      Successfully uninstalled MarkupSafe-2.1.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.6.0\n",
            "    Uninstalling fsspec-2023.6.0:\n",
            "      Successfully uninstalled fsspec-2023.6.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.13.1\n",
            "    Uninstalling filelock-3.13.1:\n",
            "      Successfully uninstalled filelock-3.13.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.7.22\n",
            "    Uninstalling certifi-2023.7.22:\n",
            "      Successfully uninstalled certifi-2023.7.22\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: sentry-sdk\n",
            "    Found existing installation: sentry-sdk 1.37.1\n",
            "    Uninstalling sentry-sdk-1.37.1:\n",
            "      Successfully uninstalled sentry-sdk-1.37.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.17.3\n",
            "    Uninstalling google-auth-2.17.3:\n",
            "      Successfully uninstalled google-auth-2.17.3\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.16.0\n",
            "    Uninstalling wandb-0.16.0:\n",
            "      Successfully uninstalled wandb-0.16.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.15.0\n",
            "    Uninstalling datasets-2.15.0:\n",
            "      Successfully uninstalled datasets-2.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.4.0 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.17.3, but you have google-auth 2.23.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.1 which is incompatible.\n",
            "ibis-framework 6.2.0 requires pyarrow<13,>=2, but you have pyarrow 14.0.0 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 14.0.0 which is incompatible.\n",
            "tensorflow 2.14.0 requires tensorboard<2.15,>=2.14, but you have tensorboard 2.15.1 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires absl-py<2.0.0,>=0.9, but you have absl-py 2.0.0 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\n",
            "yfinance 0.2.31 requires requests>=2.31, but you have requests 2.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.2 Pillow-9.3.0 absl-py-2.0.0 black-23.10.1 certifi-2022.12.7 charset-normalizer-2.1.1 datasets-2.14.6 filelock-3.9.0 fsspec-2023.4.0 google-auth-2.23.4 google-auth-oauthlib-1.1.0 huggingface-hub-0.17.3 mypy-extensions-1.0.0 networkx-3.0 numpy-1.26.1 pandas-2.1.2 pathspec-0.11.2 pathtools-0.1.2 platformdirs-3.11.0 protobuf-4.23.4 psutil-5.9.6 pyarrow-14.0.0 pynvim-0.4.3 regex-2023.10.3 requests-2.28.1 sentry-sdk-1.34.0 tensorboard-2.15.1 tokenizers-0.14.1 transformers-4.35.0 typing_extensions-4.4.0 tzdata-2023.3 urllib3-1.26.13 wandb-0.15.12\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "google",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%cd\n",
        "!git clone https://github.com/ReaLLMASIC/nanoGPT.git nanoGPT_cpu\n",
        "%cd nanoGPT_cpu\n",
        "\n",
        "# check branch info\n",
        "!echo \"Cloned repository\"\n",
        "!git branch\n",
        "\n",
        "!ls\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cpu\n",
        "!pip install numpy transformers datasets tiktoken wandb tqdm tensorboard\n",
        "!pip install -r requirements_cpu.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "### **Run a Small Network on CPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gE-Ez1qtyIA",
        "outputId": "6eccf132-08fc-4938-e2a2-3d2f67c24cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 1,115,394\n",
            "all the unique characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n",
            "train has 1,003,854 tokens\n",
            "val has 111,540 tokens\n",
            "2023-11-25 17:59:31.800170: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-25 17:59:31.848450: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-25 17:59:31.848496: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-25 17:59:31.848542: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-25 17:59:31.857306: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-25 17:59:32.845127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "{'block_size': 128, 'n_layer': 6, 'n_head': 6, 'n_embd': 126, 'dropout': 0.2, 'bias': False, 'use_post_ln': False, 'use_rmsnorm': True, 'use_rotary_embeddings': True, 'rope_variant': 'rope', 'shortrope_length': 16, 'use_abs_pos_embeddings': False, 'use_softmax_variant': False, 'softmax_variant': 'softermax', 'use_softermax_xmax': False, 'strongermax_strength': 2}\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "number of parameters: 1.15M\n",
            "num decayed parameter tensors: 26, with 1,167,390 parameters\n",
            "num non-decayed parameter tensors: 13, with 1,638 parameters\n",
            "using fused AdamW: False\n",
            "step 0: train loss 4.3277, val loss 4.3219\n",
            "iter 0: loss 4.2949, time 37793.45ms, mfu -100.00%\n",
            "iter 150: loss 2.4864, time 367.59ms, mfu 0.06%\n",
            "step 300: train loss 2.3726, val loss 2.3858\n",
            "saving checkpoint to out\n",
            "iter 300: loss 2.3975, time 35052.33ms, mfu 0.05%\n",
            "iter 450: loss 2.3166, time 366.42ms, mfu 0.05%\n"
          ]
        }
      ],
      "source": [
        "!python3 data/shakespeare_char/prepare.py\n",
        "!python3 train.py --out_dir=out --device=cpu --eval_interval=300 --log_interval=150 --block_size=128 --batch_size=64 --n_layer=6 --n_head=6 --n_embd=126 --max_iters=2000 --lr_decay_iters=2 --dropout=0.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "### **Run CPU Inference**\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4HZx7Gndbrh"
      },
      "outputs": [],
      "source": [
        "!python3 sample.py --device=cpu --out_dir=\"out\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "# **GPU Quickstart**\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "swIfEfkhpCSZ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Qfh9x6myI9g"
      },
      "source": [
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "### **Install NanoGPT GPU Dependencies**\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd\n",
        "!git clone https://github.com/ReaLLMASIC/nanoGPT.git nanoGPT_gpu\n",
        "%cd nanoGPT_gpu\n",
        "\n",
        "# check branch info\n",
        "!echo \"Cloned repository\"\n",
        "!git branch\n",
        "\n",
        "!ls\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install numpy transformers datasets tiktoken wandb tqdm tensorboard\n"
      ],
      "metadata": {
        "id": "z9TWJn8PpJLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a80cbd-99dd-4a38-f98b-1f54efcc607f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "fatal: destination path 'nanoGPT_gpu' already exists and is not an empty directory.\n",
            "/root/nanoGPT_gpu\n",
            "Cloned repository\n",
            "* \u001b[32mmaster\u001b[m\n",
            "assets\t\t\t  install_llama_cpp_python.sh  requirements_cpu.txt\n",
            "bench.py\t\t  LICENSE\t\t       sample.py\n",
            "config\t\t\t  logs\t\t\t       scaling_laws.ipynb\n",
            "Contributing_Features.md  model.py\t\t       start_tensorboard.sh\n",
            "data\t\t\t  modules\t\t       train.py\n",
            "data_augmentation\t  out\t\t\t       transformer_sizing.ipynb\n",
            "explorations\t\t  __pycache__\n",
            "HW\t\t\t  README.md\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (2.14.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.40)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.37.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.59.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.5.1)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard) (3.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard) (3.2.2)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Za1OziLayNmh"
      },
      "source": [
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "### **Run GPU Training**\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py --device=\"cuda\" --dtype=\"float16\" --max_iters=3500"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-c73d8WyfIZ",
        "outputId": "6747d660-5604-41b9-aa3c-aebce2e2fe56"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-25 18:46:52.710826: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-25 18:46:52.710888: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-25 18:46:52.710933: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-25 18:46:52.735337: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-25 18:46:54.064475: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "{'block_size': 256, 'n_layer': 6, 'n_head': 6, 'n_embd': 384, 'dropout': 0.2, 'bias': False, 'use_post_ln': False, 'use_rmsnorm': True, 'use_rotary_embeddings': True, 'rope_variant': 'rope', 'shortrope_length': 16, 'use_abs_pos_embeddings': False, 'use_softmax_variant': False, 'softmax_variant': 'softermax', 'use_softermax_xmax': False, 'strongermax_strength': 2}\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "number of parameters: 10.65M\n",
            "num decayed parameter tensors: 26, with 10,740,096 parameters\n",
            "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 7.5426, val loss 7.5307\n",
            "iter 0: loss 6.7767, time 7312.83ms, mfu -100.00%\n",
            "iter 10: loss 3.2379, time 50.58ms, mfu 7.37%\n",
            "iter 20: loss 2.7054, time 50.13ms, mfu 7.37%\n",
            "iter 30: loss 2.6006, time 50.27ms, mfu 7.38%\n",
            "iter 40: loss 2.5579, time 50.52ms, mfu 7.38%\n",
            "iter 50: loss 2.5198, time 51.17ms, mfu 7.37%\n",
            "iter 60: loss 2.5089, time 50.26ms, mfu 7.37%\n",
            "iter 70: loss 2.4979, time 50.94ms, mfu 7.37%\n",
            "iter 80: loss 2.5032, time 51.23ms, mfu 7.36%\n",
            "iter 90: loss 2.4718, time 50.40ms, mfu 7.36%\n",
            "iter 100: loss 2.4704, time 50.32ms, mfu 7.37%\n",
            "iter 110: loss 2.4668, time 51.35ms, mfu 7.35%\n",
            "iter 120: loss 2.4549, time 51.15ms, mfu 7.35%\n",
            "iter 130: loss 2.4388, time 51.02ms, mfu 7.34%\n",
            "iter 140: loss 2.4444, time 52.02ms, mfu 7.33%\n",
            "iter 150: loss 2.4633, time 51.23ms, mfu 7.32%\n",
            "iter 160: loss 2.4392, time 50.95ms, mfu 7.32%\n",
            "iter 170: loss 2.4234, time 51.43ms, mfu 7.31%\n",
            "iter 180: loss 2.4245, time 52.33ms, mfu 7.29%\n",
            "iter 190: loss 2.3926, time 52.04ms, mfu 7.28%\n",
            "iter 200: loss 2.3787, time 51.98ms, mfu 7.27%\n",
            "iter 210: loss 2.3520, time 50.33ms, mfu 7.28%\n",
            "iter 220: loss 2.3704, time 50.41ms, mfu 7.29%\n",
            "iter 230: loss 2.3463, time 50.36ms, mfu 7.30%\n",
            "iter 240: loss 2.3597, time 50.65ms, mfu 7.31%\n",
            "step 250: train loss 2.2812, val loss 2.3103\n",
            "saving checkpoint to out\n",
            "iter 250: loss 2.3052, time 6717.37ms, mfu 6.58%\n",
            "iter 260: loss 2.2868, time 50.30ms, mfu 6.67%\n",
            "iter 270: loss 2.2690, time 50.36ms, mfu 6.74%\n",
            "iter 280: loss 2.2916, time 51.42ms, mfu 6.79%\n",
            "iter 290: loss 2.2315, time 53.71ms, mfu 6.80%\n",
            "iter 300: loss 2.2308, time 51.50ms, mfu 6.85%\n",
            "iter 310: loss 2.2056, time 51.62ms, mfu 6.89%\n",
            "iter 320: loss 2.1836, time 61.51ms, mfu 6.80%\n",
            "iter 330: loss 2.1328, time 51.38ms, mfu 6.85%\n",
            "iter 340: loss 2.1084, time 51.08ms, mfu 6.89%\n",
            "iter 350: loss 2.1332, time 52.96ms, mfu 6.91%\n",
            "iter 360: loss 2.0800, time 53.60ms, mfu 6.91%\n",
            "iter 370: loss 2.0605, time 53.21ms, mfu 6.92%\n",
            "iter 380: loss 2.0199, time 50.71ms, mfu 6.96%\n",
            "iter 390: loss 2.0332, time 50.39ms, mfu 7.01%\n",
            "iter 400: loss 2.0687, time 50.54ms, mfu 7.04%\n",
            "iter 410: loss 1.9953, time 50.35ms, mfu 7.08%\n",
            "iter 420: loss 1.9901, time 50.29ms, mfu 7.11%\n",
            "iter 430: loss 1.9602, time 50.46ms, mfu 7.14%\n",
            "iter 440: loss 1.9154, time 50.68ms, mfu 7.16%\n",
            "iter 450: loss 1.9057, time 50.41ms, mfu 7.18%\n",
            "iter 460: loss 1.8557, time 50.50ms, mfu 7.20%\n",
            "iter 470: loss 1.9122, time 50.53ms, mfu 7.22%\n",
            "iter 480: loss 1.8682, time 50.57ms, mfu 7.23%\n",
            "iter 490: loss 1.8452, time 50.28ms, mfu 7.25%\n",
            "step 500: train loss 1.7595, val loss 1.9111\n",
            "saving checkpoint to out\n",
            "iter 500: loss 1.8411, time 7085.28ms, mfu 6.53%\n",
            "iter 510: loss 1.8493, time 52.80ms, mfu 6.58%\n",
            "iter 520: loss 1.8282, time 53.72ms, mfu 6.62%\n",
            "iter 530: loss 1.8037, time 52.45ms, mfu 6.67%\n",
            "iter 540: loss 1.8354, time 52.89ms, mfu 6.71%\n",
            "iter 550: loss 1.7812, time 50.40ms, mfu 6.77%\n",
            "iter 560: loss 1.7889, time 50.62ms, mfu 6.83%\n",
            "iter 570: loss 1.7752, time 51.60ms, mfu 6.87%\n",
            "iter 580: loss 1.7609, time 50.36ms, mfu 6.92%\n",
            "iter 590: loss 1.7221, time 50.32ms, mfu 6.97%\n",
            "iter 600: loss 1.7404, time 50.36ms, mfu 7.02%\n",
            "iter 610: loss 1.7547, time 50.45ms, mfu 7.05%\n",
            "iter 620: loss 1.7313, time 51.30ms, mfu 7.07%\n",
            "iter 630: loss 1.7325, time 51.34ms, mfu 7.09%\n",
            "iter 640: loss 1.6841, time 50.85ms, mfu 7.12%\n",
            "iter 650: loss 1.7257, time 50.62ms, mfu 7.14%\n",
            "iter 660: loss 1.7215, time 51.35ms, mfu 7.15%\n",
            "iter 670: loss 1.6818, time 50.37ms, mfu 7.18%\n",
            "iter 680: loss 1.7181, time 50.78ms, mfu 7.19%\n",
            "iter 690: loss 1.6755, time 50.57ms, mfu 7.21%\n",
            "iter 700: loss 1.6901, time 50.52ms, mfu 7.23%\n",
            "iter 710: loss 1.6610, time 50.94ms, mfu 7.24%\n",
            "iter 720: loss 1.6476, time 50.57ms, mfu 7.25%\n",
            "iter 730: loss 1.6356, time 50.40ms, mfu 7.26%\n",
            "iter 740: loss 1.6372, time 52.97ms, mfu 7.24%\n",
            "step 750: train loss 1.5627, val loss 1.7583\n",
            "saving checkpoint to out\n",
            "iter 750: loss 1.6226, time 7383.67ms, mfu 6.52%\n",
            "iter 760: loss 1.6561, time 50.51ms, mfu 6.61%\n",
            "iter 770: loss 1.6381, time 50.55ms, mfu 6.68%\n",
            "iter 780: loss 1.6343, time 50.57ms, mfu 6.75%\n",
            "iter 790: loss 1.6281, time 50.54ms, mfu 6.81%\n",
            "iter 800: loss 1.6340, time 50.52ms, mfu 6.87%\n",
            "iter 810: loss 1.6144, time 50.70ms, mfu 6.92%\n",
            "iter 820: loss 1.6177, time 50.67ms, mfu 6.96%\n",
            "iter 830: loss 1.5980, time 50.73ms, mfu 7.00%\n",
            "iter 840: loss 1.6138, time 50.63ms, mfu 7.04%\n",
            "iter 850: loss 1.5969, time 50.42ms, mfu 7.07%\n",
            "iter 860: loss 1.6037, time 51.03ms, mfu 7.09%\n",
            "iter 870: loss 1.6049, time 50.33ms, mfu 7.13%\n",
            "iter 880: loss 1.5867, time 50.49ms, mfu 7.15%\n",
            "iter 890: loss 1.5979, time 50.56ms, mfu 7.17%\n",
            "iter 900: loss 1.5981, time 54.65ms, mfu 7.14%\n",
            "iter 910: loss 1.5366, time 51.38ms, mfu 7.15%\n",
            "iter 920: loss 1.5749, time 51.15ms, mfu 7.16%\n",
            "iter 930: loss 1.5657, time 51.34ms, mfu 7.17%\n",
            "iter 940: loss 1.5483, time 51.42ms, mfu 7.18%\n",
            "iter 950: loss 1.5638, time 51.63ms, mfu 7.18%\n",
            "iter 960: loss 1.5751, time 51.56ms, mfu 7.19%\n",
            "iter 970: loss 1.5766, time 51.52ms, mfu 7.19%\n",
            "iter 980: loss 1.5712, time 52.68ms, mfu 7.18%\n",
            "iter 990: loss 1.5529, time 53.75ms, mfu 7.16%\n",
            "step 1000: train loss 1.4858, val loss 1.6788\n",
            "saving checkpoint to out\n",
            "iter 1000: loss 1.5419, time 6746.94ms, mfu 6.45%\n",
            "iter 1010: loss 1.5374, time 50.66ms, mfu 6.54%\n",
            "iter 1020: loss 1.5249, time 50.56ms, mfu 6.62%\n",
            "iter 1030: loss 1.5514, time 50.90ms, mfu 6.69%\n",
            "iter 1040: loss 1.5722, time 50.40ms, mfu 6.76%\n",
            "iter 1050: loss 1.4968, time 50.97ms, mfu 6.82%\n",
            "iter 1060: loss 1.5619, time 50.55ms, mfu 6.87%\n",
            "iter 1070: loss 1.5519, time 53.81ms, mfu 6.88%\n",
            "iter 1080: loss 1.5514, time 51.54ms, mfu 6.91%\n",
            "iter 1090: loss 1.5638, time 51.15ms, mfu 6.95%\n",
            "iter 1100: loss 1.5454, time 51.07ms, mfu 6.98%\n",
            "iter 1110: loss 1.5101, time 51.18ms, mfu 7.01%\n",
            "iter 1120: loss 1.5140, time 51.54ms, mfu 7.04%\n",
            "iter 1130: loss 1.5189, time 51.61ms, mfu 7.05%\n",
            "iter 1140: loss 1.5156, time 51.42ms, mfu 7.07%\n",
            "iter 1150: loss 1.5212, time 52.37ms, mfu 7.08%\n",
            "iter 1160: loss 1.5592, time 52.74ms, mfu 7.08%\n",
            "iter 1170: loss 1.5331, time 53.15ms, mfu 7.07%\n",
            "iter 1180: loss 1.5322, time 50.50ms, mfu 7.10%\n",
            "iter 1190: loss 1.4932, time 50.71ms, mfu 7.13%\n",
            "iter 1200: loss 1.5054, time 50.36ms, mfu 7.15%\n",
            "iter 1210: loss 1.4913, time 50.44ms, mfu 7.18%\n",
            "iter 1220: loss 1.5307, time 50.72ms, mfu 7.19%\n",
            "iter 1230: loss 1.5315, time 50.56ms, mfu 7.21%\n",
            "iter 1240: loss 1.5132, time 50.52ms, mfu 7.23%\n",
            "step 1250: train loss 1.4362, val loss 1.6549\n",
            "saving checkpoint to out\n",
            "iter 1250: loss 1.4961, time 6859.27ms, mfu 6.51%\n",
            "iter 1260: loss 1.5100, time 51.44ms, mfu 6.58%\n",
            "iter 1270: loss 1.4865, time 51.14ms, mfu 6.65%\n",
            "iter 1280: loss 1.4803, time 51.14ms, mfu 6.72%\n",
            "iter 1290: loss 1.5187, time 51.22ms, mfu 6.77%\n",
            "iter 1300: loss 1.5268, time 51.30ms, mfu 6.82%\n",
            "iter 1310: loss 1.4506, time 51.35ms, mfu 6.87%\n",
            "iter 1320: loss 1.5328, time 53.49ms, mfu 6.88%\n",
            "iter 1330: loss 1.4869, time 55.40ms, mfu 6.86%\n",
            "iter 1340: loss 1.5180, time 52.63ms, mfu 6.88%\n",
            "iter 1350: loss 1.4816, time 50.28ms, mfu 6.94%\n",
            "iter 1360: loss 1.5031, time 50.73ms, mfu 6.98%\n",
            "iter 1370: loss 1.4760, time 50.37ms, mfu 7.02%\n",
            "iter 1380: loss 1.4911, time 50.85ms, mfu 7.05%\n",
            "iter 1390: loss 1.4864, time 50.46ms, mfu 7.08%\n",
            "iter 1400: loss 1.4901, time 50.39ms, mfu 7.11%\n",
            "iter 1410: loss 1.4785, time 50.43ms, mfu 7.14%\n",
            "iter 1420: loss 1.4966, time 50.90ms, mfu 7.16%\n",
            "iter 1430: loss 1.4730, time 50.68ms, mfu 7.18%\n",
            "iter 1440: loss 1.4912, time 50.55ms, mfu 7.20%\n",
            "iter 1450: loss 1.4559, time 50.72ms, mfu 7.21%\n",
            "iter 1460: loss 1.4679, time 50.46ms, mfu 7.23%\n",
            "iter 1470: loss 1.4533, time 51.39ms, mfu 7.23%\n",
            "iter 1480: loss 1.4584, time 50.56ms, mfu 7.25%\n",
            "iter 1490: loss 1.4689, time 50.56ms, mfu 7.26%\n",
            "step 1500: train loss 1.3912, val loss 1.6079\n",
            "saving checkpoint to out\n",
            "iter 1500: loss 1.4259, time 7269.54ms, mfu 6.54%\n",
            "iter 1510: loss 1.4778, time 50.59ms, mfu 6.62%\n",
            "iter 1520: loss 1.4550, time 50.29ms, mfu 6.70%\n",
            "iter 1530: loss 1.4941, time 50.45ms, mfu 6.77%\n",
            "iter 1540: loss 1.4303, time 50.57ms, mfu 6.83%\n",
            "iter 1550: loss 1.4712, time 50.69ms, mfu 6.88%\n",
            "iter 1560: loss 1.4568, time 50.35ms, mfu 6.93%\n",
            "iter 1570: loss 1.4817, time 51.08ms, mfu 6.97%\n",
            "iter 1580: loss 1.4440, time 50.60ms, mfu 7.01%\n",
            "iter 1590: loss 1.4393, time 50.63ms, mfu 7.04%\n",
            "iter 1600: loss 1.4424, time 50.56ms, mfu 7.08%\n",
            "iter 1610: loss 1.4778, time 50.61ms, mfu 7.10%\n",
            "iter 1620: loss 1.4204, time 50.59ms, mfu 7.13%\n",
            "iter 1630: loss 1.4534, time 50.59ms, mfu 7.15%\n",
            "iter 1640: loss 1.4468, time 50.38ms, mfu 7.18%\n",
            "iter 1650: loss 1.4165, time 50.73ms, mfu 7.20%\n",
            "iter 1660: loss 1.4588, time 50.52ms, mfu 7.21%\n",
            "iter 1670: loss 1.4470, time 50.47ms, mfu 7.23%\n",
            "iter 1680: loss 1.4454, time 50.58ms, mfu 7.24%\n",
            "iter 1690: loss 1.4589, time 50.70ms, mfu 7.25%\n",
            "iter 1700: loss 1.4419, time 50.21ms, mfu 7.27%\n",
            "iter 1710: loss 1.4261, time 51.35ms, mfu 7.27%\n",
            "iter 1720: loss 1.4361, time 50.94ms, mfu 7.27%\n",
            "iter 1730: loss 1.4443, time 51.06ms, mfu 7.28%\n",
            "iter 1740: loss 1.4201, time 51.32ms, mfu 7.27%\n",
            "step 1750: train loss 1.3589, val loss 1.5852\n",
            "saving checkpoint to out\n",
            "iter 1750: loss 1.4413, time 7038.90ms, mfu 6.55%\n",
            "iter 1760: loss 1.4366, time 50.43ms, mfu 6.64%\n",
            "iter 1770: loss 1.4415, time 51.13ms, mfu 6.70%\n",
            "iter 1780: loss 1.4439, time 50.75ms, mfu 6.77%\n",
            "iter 1790: loss 1.4384, time 50.44ms, mfu 6.83%\n",
            "iter 1800: loss 1.4308, time 50.46ms, mfu 6.88%\n",
            "iter 1810: loss 1.4050, time 50.55ms, mfu 6.93%\n",
            "iter 1820: loss 1.4229, time 50.47ms, mfu 6.98%\n",
            "iter 1830: loss 1.4348, time 50.66ms, mfu 7.02%\n",
            "iter 1840: loss 1.4104, time 50.69ms, mfu 7.05%\n",
            "iter 1850: loss 1.4197, time 50.58ms, mfu 7.08%\n",
            "iter 1860: loss 1.4275, time 50.80ms, mfu 7.11%\n",
            "iter 1870: loss 1.3890, time 50.39ms, mfu 7.13%\n",
            "iter 1880: loss 1.4311, time 54.07ms, mfu 7.11%\n",
            "iter 1890: loss 1.4377, time 51.59ms, mfu 7.12%\n",
            "iter 1900: loss 1.3943, time 51.12ms, mfu 7.14%\n",
            "iter 1910: loss 1.4341, time 51.47ms, mfu 7.15%\n",
            "iter 1920: loss 1.4272, time 52.43ms, mfu 7.14%\n",
            "iter 1930: loss 1.4078, time 51.52ms, mfu 7.15%\n",
            "iter 1940: loss 1.4033, time 52.97ms, mfu 7.14%\n",
            "iter 1950: loss 1.3987, time 52.01ms, mfu 7.14%\n",
            "iter 1960: loss 1.4238, time 53.39ms, mfu 7.13%\n",
            "iter 1970: loss 1.4010, time 53.01ms, mfu 7.12%\n",
            "iter 1980: loss 1.4210, time 50.48ms, mfu 7.14%\n",
            "iter 1990: loss 1.4049, time 50.58ms, mfu 7.17%\n",
            "step 2000: train loss 1.3362, val loss 1.5780\n",
            "saving checkpoint to out\n",
            "iter 2000: loss 1.4167, time 6745.04ms, mfu 6.46%\n",
            "iter 2010: loss 1.4067, time 50.57ms, mfu 6.55%\n",
            "iter 2020: loss 1.3905, time 50.29ms, mfu 6.63%\n",
            "iter 2030: loss 1.4275, time 50.39ms, mfu 6.71%\n",
            "iter 2040: loss 1.4113, time 51.58ms, mfu 6.76%\n",
            "iter 2050: loss 1.3687, time 51.31ms, mfu 6.81%\n",
            "iter 2060: loss 1.3661, time 51.22ms, mfu 6.86%\n",
            "iter 2070: loss 1.3971, time 50.99ms, mfu 6.90%\n",
            "iter 2080: loss 1.3764, time 51.29ms, mfu 6.94%\n",
            "iter 2090: loss 1.4169, time 51.22ms, mfu 6.97%\n",
            "iter 2100: loss 1.3857, time 51.41ms, mfu 7.00%\n",
            "iter 2110: loss 1.3829, time 51.59ms, mfu 7.02%\n",
            "iter 2120: loss 1.4010, time 52.10ms, mfu 7.03%\n",
            "iter 2130: loss 1.4049, time 52.47ms, mfu 7.04%\n",
            "iter 2140: loss 1.4111, time 52.79ms, mfu 7.04%\n",
            "iter 2150: loss 1.4002, time 50.41ms, mfu 7.08%\n",
            "iter 2160: loss 1.4312, time 50.34ms, mfu 7.11%\n",
            "iter 2170: loss 1.4081, time 50.48ms, mfu 7.14%\n",
            "iter 2180: loss 1.3958, time 50.45ms, mfu 7.16%\n",
            "iter 2190: loss 1.3882, time 50.71ms, mfu 7.18%\n",
            "iter 2200: loss 1.4019, time 50.47ms, mfu 7.20%\n",
            "iter 2210: loss 1.3849, time 50.59ms, mfu 7.22%\n",
            "iter 2220: loss 1.3909, time 51.30ms, mfu 7.22%\n",
            "iter 2230: loss 1.3903, time 50.30ms, mfu 7.24%\n",
            "iter 2240: loss 1.4186, time 50.42ms, mfu 7.26%\n",
            "step 2250: train loss 1.3176, val loss 1.5532\n",
            "saving checkpoint to out\n",
            "iter 2250: loss 1.3927, time 6994.67ms, mfu 6.54%\n",
            "iter 2260: loss 1.3963, time 51.10ms, mfu 6.61%\n",
            "iter 2270: loss 1.4289, time 51.33ms, mfu 6.68%\n",
            "iter 2280: loss 1.3683, time 51.54ms, mfu 6.73%\n",
            "iter 2290: loss 1.4141, time 55.00ms, mfu 6.74%\n",
            "iter 2300: loss 1.4145, time 53.02ms, mfu 6.76%\n",
            "iter 2310: loss 1.3856, time 53.03ms, mfu 6.79%\n",
            "iter 2320: loss 1.3939, time 50.63ms, mfu 6.85%\n",
            "iter 2330: loss 1.3852, time 50.57ms, mfu 6.90%\n",
            "iter 2340: loss 1.4118, time 50.48ms, mfu 6.95%\n",
            "iter 2350: loss 1.3904, time 50.33ms, mfu 6.99%\n",
            "iter 2360: loss 1.3981, time 50.55ms, mfu 7.03%\n",
            "iter 2370: loss 1.3880, time 50.58ms, mfu 7.07%\n",
            "iter 2380: loss 1.3671, time 50.36ms, mfu 7.10%\n",
            "iter 2390: loss 1.3644, time 50.59ms, mfu 7.13%\n",
            "iter 2400: loss 1.3716, time 50.47ms, mfu 7.15%\n",
            "iter 2410: loss 1.3654, time 50.68ms, mfu 7.17%\n",
            "iter 2420: loss 1.3757, time 50.46ms, mfu 7.19%\n",
            "iter 2430: loss 1.3557, time 50.60ms, mfu 7.21%\n",
            "iter 2440: loss 1.3643, time 50.76ms, mfu 7.22%\n",
            "iter 2450: loss 1.3787, time 50.39ms, mfu 7.24%\n",
            "iter 2460: loss 1.3740, time 50.77ms, mfu 7.25%\n",
            "iter 2470: loss 1.3856, time 50.46ms, mfu 7.26%\n",
            "iter 2480: loss 1.3807, time 50.47ms, mfu 7.28%\n",
            "iter 2490: loss 1.3694, time 50.81ms, mfu 7.28%\n",
            "step 2500: train loss 1.2987, val loss 1.5419\n",
            "saving checkpoint to out\n",
            "iter 2500: loss 1.3879, time 7177.44ms, mfu 6.56%\n",
            "iter 2510: loss 1.3861, time 50.47ms, mfu 6.64%\n",
            "iter 2520: loss 1.3736, time 50.49ms, mfu 6.71%\n",
            "iter 2530: loss 1.3644, time 50.51ms, mfu 6.78%\n",
            "iter 2540: loss 1.3563, time 50.46ms, mfu 6.84%\n",
            "iter 2550: loss 1.3934, time 50.40ms, mfu 6.90%\n",
            "iter 2560: loss 1.3504, time 50.65ms, mfu 6.94%\n",
            "iter 2570: loss 1.3769, time 50.77ms, mfu 6.98%\n",
            "iter 2580: loss 1.3851, time 50.40ms, mfu 7.02%\n",
            "iter 2590: loss 1.3776, time 50.64ms, mfu 7.06%\n",
            "iter 2600: loss 1.3637, time 50.80ms, mfu 7.08%\n",
            "iter 2610: loss 1.3479, time 50.67ms, mfu 7.11%\n",
            "iter 2620: loss 1.3523, time 50.70ms, mfu 7.14%\n",
            "iter 2630: loss 1.3200, time 50.33ms, mfu 7.16%\n",
            "iter 2640: loss 1.3589, time 50.52ms, mfu 7.18%\n",
            "iter 2650: loss 1.3919, time 50.65ms, mfu 7.20%\n",
            "iter 2660: loss 1.3586, time 50.61ms, mfu 7.22%\n",
            "iter 2670: loss 1.3435, time 50.45ms, mfu 7.23%\n",
            "iter 2680: loss 1.3596, time 51.21ms, mfu 7.24%\n",
            "iter 2690: loss 1.3517, time 51.40ms, mfu 7.24%\n",
            "iter 2700: loss 1.3397, time 51.06ms, mfu 7.25%\n",
            "iter 2710: loss 1.3720, time 51.79ms, mfu 7.24%\n",
            "iter 2720: loss 1.3743, time 51.21ms, mfu 7.24%\n",
            "iter 2730: loss 1.3703, time 52.92ms, mfu 7.22%\n",
            "iter 2740: loss 1.3510, time 51.02ms, mfu 7.23%\n",
            "step 2750: train loss 1.2826, val loss 1.5452\n",
            "iter 2750: loss 1.3515, time 6638.63ms, mfu 6.51%\n",
            "iter 2760: loss 1.3559, time 50.57ms, mfu 6.60%\n",
            "iter 2770: loss 1.3520, time 50.35ms, mfu 6.68%\n",
            "iter 2780: loss 1.3500, time 50.44ms, mfu 6.75%\n",
            "iter 2790: loss 1.3655, time 50.70ms, mfu 6.81%\n",
            "iter 2800: loss 1.3512, time 51.69ms, mfu 6.85%\n",
            "iter 2810: loss 1.3725, time 50.36ms, mfu 6.91%\n",
            "iter 2820: loss 1.3674, time 50.68ms, mfu 6.95%\n",
            "iter 2830: loss 1.3602, time 50.59ms, mfu 6.99%\n",
            "iter 2840: loss 1.3040, time 50.49ms, mfu 7.03%\n",
            "iter 2850: loss 1.3537, time 51.47ms, mfu 7.05%\n",
            "iter 2860: loss 1.3522, time 51.27ms, mfu 7.07%\n",
            "iter 2870: loss 1.3593, time 51.29ms, mfu 7.09%\n",
            "iter 2880: loss 1.3932, time 51.47ms, mfu 7.11%\n",
            "iter 2890: loss 1.3437, time 51.50ms, mfu 7.12%\n",
            "iter 2900: loss 1.3355, time 51.43ms, mfu 7.13%\n",
            "iter 2910: loss 1.3768, time 51.69ms, mfu 7.14%\n",
            "iter 2920: loss 1.3594, time 53.27ms, mfu 7.13%\n",
            "iter 2930: loss 1.3520, time 53.25ms, mfu 7.11%\n",
            "iter 2940: loss 1.3392, time 53.01ms, mfu 7.10%\n",
            "iter 2950: loss 1.3661, time 50.42ms, mfu 7.13%\n",
            "iter 2960: loss 1.3461, time 50.55ms, mfu 7.16%\n",
            "iter 2970: loss 1.3315, time 51.05ms, mfu 7.17%\n",
            "iter 2980: loss 1.3244, time 50.34ms, mfu 7.19%\n",
            "iter 2990: loss 1.3393, time 50.47ms, mfu 7.21%\n",
            "step 3000: train loss 1.2689, val loss 1.5310\n",
            "saving checkpoint to out\n",
            "iter 3000: loss 1.3257, time 6738.44ms, mfu 6.50%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsR_dPeVyVJ8"
      },
      "source": [
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "### **Run GPU Inference**\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 sample.py --out_dir=\"out\" --device=\"cuda\" --dtype=\"float16\" --num_samples=1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkqxTfU_yUrK",
        "outputId": "d45c6eef-f2aa-487c-dd7b-f63dd8e2be40"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/root/nanoGPT_gpu/data/csv_data/sample.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "# **CSV Data Training**\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "oGjK3xvh09AP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "## **Prepare sample data**\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "ZDfk_t7K3cun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd\n",
        "%cd nanoGPT_gpu\n",
        "%cd data/csv_data\n",
        "%ls\n",
        "!bash example_sine_and_noise.sh\n",
        "!tail processed_sine_data.csv\n",
        "!python3 prepare.py -i processed_sine_data.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUdV_T2V1Z6U",
        "outputId": "a1b33a5b-4010-4990-f7a7-f75c17dfe0fa"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "/root/nanoGPT_gpu\n",
            "/root/nanoGPT_gpu/data/csv_data\n",
            "app.py                     prepare.py                sine_noise_sn_shuffled.csv\n",
            "clean.sh                   process_csv.py            sine_time_data_unshuffled_recombined.csv\n",
            "combine_csvs.py            processed_sine_data.csv   \u001b[0m\u001b[01;34mtemplates\u001b[0m/\n",
            "data_sine_data.csv         README.md                 time_sine_data.csv\n",
            "example_sine_and_noise.sh  \u001b[01;34mresults\u001b[0m/                  train.bin\n",
            "main.sh                    sine_data_unshuffled.csv  unprocess.py\n",
            "meta.pkl                   sine_noise_generator.py   val.bin\n",
            "+ python3 sine_noise_generator.py --noise_level 0.3 --filename sine_data.csv --scientific --precision 2 --modulo 10000 --points 1000 --split\n",
            "Time data saved to time_sine_data.csv\n",
            "Signal data saved to data_sine_data.csv\n",
            "+ set +x\n",
            "\n",
            "Preview: Generated Times\n",
            "0.00e+00\n",
            "1.00e+00\n",
            "2.00e+00\n",
            "3.00e+00\n",
            "4.00e+00\n",
            "5.00e+00\n",
            "6.00e+00\n",
            "7.00e+00\n",
            "8.00e+00\n",
            "9.00e+00\n",
            "\n",
            "\n",
            "Preview: Generated Data\n",
            "0.00e+00,-5.56e-02,-5.56e-02\n",
            "6.28e-02,3.63e-02,9.91e-02\n",
            "1.25e-01,9.20e-02,2.17e-01\n",
            "1.87e-01,3.47e-02,2.22e-01\n",
            "2.49e-01,-4.99e-02,1.99e-01\n",
            "3.09e-01,1.21e-02,3.21e-01\n",
            "3.68e-01,-9.02e-02,2.78e-01\n",
            "4.26e-01,-2.46e-01,1.80e-01\n",
            "4.82e-01,-2.73e-01,2.09e-01\n",
            "5.36e-01,-3.20e-02,5.04e-01\n",
            "\n",
            "\n",
            "\n",
            "+ python3 process_csv.py data_sine_data.csv sine_noise_sn_shuffled.csv --shuffle --exclude e\n",
            "+ set +x\n",
            "\n",
            "Preview: Shuffled Data\n",
            "a0.00e+00c-5.56e-02b-5.56e-02\n",
            "c9.91e-02a6.28e-02b3.63e-02\n",
            "b9.20e-02c2.17e-01a1.25e-01\n",
            "c2.22e-01a1.87e-01b3.47e-02\n",
            "b-4.99e-02c1.99e-01a2.49e-01\n",
            "c3.21e-01b1.21e-02a3.09e-01\n",
            "b-9.02e-02c2.78e-01a3.68e-01\n",
            "a4.26e-01b-2.46e-01c1.80e-01\n",
            "b-2.73e-01c2.09e-01a4.82e-01\n",
            "b-3.20e-02c5.04e-01a5.36e-01\n",
            "\n",
            "\n",
            "\n",
            "+ python3 combine_csvs.py -l time_sine_data.csv -r sine_noise_sn_shuffled.csv -o processed_sine_data.csv\n",
            "+ set +x\n",
            "\n",
            "Preview: Timestamps with Shuffled Data -- Use This For Training\n",
            "0.00e+00a0.00e+00c-5.56e-02b-5.56e-02\n",
            "1.00e+00c9.91e-02a6.28e-02b3.63e-02\n",
            "2.00e+00b9.20e-02c2.17e-01a1.25e-01\n",
            "3.00e+00c2.22e-01a1.87e-01b3.47e-02\n",
            "4.00e+00b-4.99e-02c1.99e-01a2.49e-01\n",
            "5.00e+00c3.21e-01b1.21e-02a3.09e-01\n",
            "6.00e+00b-9.02e-02c2.78e-01a3.68e-01\n",
            "7.00e+00a4.26e-01b-2.46e-01c1.80e-01\n",
            "8.00e+00b-2.73e-01c2.09e-01a4.82e-01\n",
            "9.00e+00b-3.20e-02c5.04e-01a5.36e-01\n",
            "+ python3 unprocess.py -i sine_noise_sn_shuffled.csv -o sine_data_unshuffled.csv -l abc -c\n",
            "+ set +x\n",
            "\n",
            "Preview: Undo shuffling Of Data\n",
            "0.00e+00,-5.56e-02,-5.56e-02\n",
            "6.28e-02,3.63e-02,9.91e-02\n",
            "1.25e-01,9.20e-02,2.17e-01\n",
            "1.87e-01,3.47e-02,2.22e-01\n",
            "2.49e-01,-4.99e-02,1.99e-01\n",
            "3.09e-01,1.21e-02,3.21e-01\n",
            "3.68e-01,-9.02e-02,2.78e-01\n",
            "4.26e-01,-2.46e-01,1.80e-01\n",
            "4.82e-01,-2.73e-01,2.09e-01\n",
            "5.36e-01,-3.20e-02,5.04e-01\n",
            "+ python3 combine_csvs.py -l time_sine_data.csv -r sine_data_unshuffled.csv -o sine_time_data_unshuffled_recombined.csv -d,\n",
            "+ set +x\n",
            "\n",
            "Preview: recombined data\n",
            "0.00e+00,0.00e+00,-5.56e-02,-5.56e-02\n",
            "1.00e+00,6.28e-02,3.63e-02,9.91e-02\n",
            "2.00e+00,1.25e-01,9.20e-02,2.17e-01\n",
            "3.00e+00,1.87e-01,3.47e-02,2.22e-01\n",
            "4.00e+00,2.49e-01,-4.99e-02,1.99e-01\n",
            "5.00e+00,3.09e-01,1.21e-02,3.21e-01\n",
            "6.00e+00,3.68e-01,-9.02e-02,2.78e-01\n",
            "7.00e+00,4.26e-01,-2.46e-01,1.80e-01\n",
            "8.00e+00,4.82e-01,-2.73e-01,2.09e-01\n",
            "9.00e+00,5.36e-01,-3.20e-02,5.04e-01\n",
            "+ results_plot_dir=./results/\n",
            "+ '[' '!' -d ./results/ ']'\n",
            "+ cp sine_time_data_unshuffled_recombined.csv ./results/\n",
            "+ set +x\n",
            "\n",
            "Process overview complete: use 'python3 app.py results' to view recombined graph\n",
            "9.90e+02b-1.52e-01a-5.88e-01c-7.40e-01\n",
            "9.91e+02a-5.36e-01c-5.91e-01b-5.53e-02\n",
            "9.92e+02a-4.82e-01b-7.59e-02c-5.58e-01\n",
            "9.93e+02a-4.26e-01c-5.68e-01b-1.43e-01\n",
            "9.94e+02b-7.29e-02a-3.68e-01c-4.41e-01\n",
            "9.95e+02c-4.94e-01b-1.85e-01a-3.09e-01\n",
            "9.96e+02a-2.49e-01c2.72e-01b5.21e-01\n",
            "9.97e+02b2.85e-01a-1.87e-01c9.76e-02\n",
            "9.98e+02c-2.00e-01a-1.25e-01b-7.43e-02\n",
            "9.99e+02a-6.28e-02c2.46e-01b3.08e-01\n",
            "Length of dataset: 37,493\n",
            "Unique chars: \n",
            "+-.0123456789abce\n",
            "Vocab size: 18\n",
            "Train tokens: 33,743\n",
            "Val tokens: 3,750\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd\n",
        "%cd nanoGPT_gpu\n",
        "!python3 train.py --dataset=\"csv_data\" --dtype=\"float16\" --device=\"cuda\" --max_iters=2100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCKu4fDR1kp0",
        "outputId": "916947f1-9b37-49fe-e78f-c09b02cd8028"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "/root/nanoGPT_gpu\n",
            "2023-11-25 19:01:32.933906: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-25 19:01:32.933967: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-25 19:01:32.934013: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-25 19:01:32.945734: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-25 19:01:34.314286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "{'block_size': 256, 'n_layer': 6, 'n_head': 6, 'n_embd': 384, 'dropout': 0.2, 'bias': False, 'use_post_ln': False, 'use_rmsnorm': True, 'use_rotary_embeddings': True, 'rope_variant': 'rope', 'shortrope_length': 16, 'use_abs_pos_embeddings': False, 'use_softmax_variant': False, 'softmax_variant': 'softermax', 'use_softermax_xmax': False, 'strongermax_strength': 2}\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "number of parameters: 10.63M\n",
            "num decayed parameter tensors: 26, with 10,722,048 parameters\n",
            "num non-decayed parameter tensors: 13, with 4,992 parameters\n",
            "using fused AdamW: True\n",
            "step 0: train loss 7.4354, val loss 7.4267\n",
            "iter 0: loss 6.6586, time 7093.53ms, mfu -100.00%\n",
            "iter 10: loss 1.9595, time 51.36ms, mfu 7.24%\n",
            "iter 20: loss 1.7783, time 50.90ms, mfu 7.25%\n",
            "iter 30: loss 1.7153, time 51.65ms, mfu 7.25%\n",
            "iter 40: loss 1.7052, time 52.57ms, mfu 7.23%\n",
            "iter 50: loss 1.6492, time 51.91ms, mfu 7.22%\n",
            "iter 60: loss 1.6232, time 52.93ms, mfu 7.20%\n",
            "iter 70: loss 1.5626, time 50.29ms, mfu 7.22%\n",
            "iter 80: loss 1.5339, time 50.38ms, mfu 7.24%\n",
            "iter 90: loss 1.4898, time 50.13ms, mfu 7.26%\n",
            "iter 100: loss 1.4188, time 50.12ms, mfu 7.27%\n",
            "iter 110: loss 1.3596, time 50.36ms, mfu 7.29%\n",
            "iter 120: loss 1.2788, time 50.05ms, mfu 7.30%\n",
            "iter 130: loss 1.2241, time 50.06ms, mfu 7.31%\n",
            "iter 140: loss 1.1878, time 50.07ms, mfu 7.33%\n",
            "iter 150: loss 1.1265, time 50.57ms, mfu 7.33%\n",
            "iter 160: loss 1.0986, time 50.04ms, mfu 7.34%\n",
            "iter 170: loss 1.0726, time 50.16ms, mfu 7.35%\n",
            "iter 180: loss 1.0607, time 50.13ms, mfu 7.35%\n",
            "iter 190: loss 1.0348, time 50.05ms, mfu 7.36%\n",
            "iter 200: loss 1.0240, time 50.24ms, mfu 7.37%\n",
            "iter 210: loss 1.0301, time 50.25ms, mfu 7.37%\n",
            "iter 220: loss 1.0157, time 50.21ms, mfu 7.37%\n",
            "iter 230: loss 1.0023, time 50.26ms, mfu 7.38%\n",
            "iter 240: loss 0.9986, time 50.38ms, mfu 7.38%\n",
            "step 250: train loss 0.9448, val loss 0.9756\n",
            "saving checkpoint to out\n",
            "iter 250: loss 0.9682, time 7190.63ms, mfu 6.65%\n",
            "iter 260: loss 0.9742, time 50.14ms, mfu 6.72%\n",
            "iter 270: loss 0.9612, time 50.35ms, mfu 6.79%\n",
            "iter 280: loss 0.9738, time 50.43ms, mfu 6.85%\n",
            "iter 290: loss 0.9781, time 50.19ms, mfu 6.90%\n",
            "iter 300: loss 0.9469, time 50.34ms, mfu 6.95%\n",
            "iter 310: loss 0.9288, time 50.11ms, mfu 7.00%\n",
            "iter 320: loss 0.9366, time 50.34ms, mfu 7.04%\n",
            "iter 330: loss 0.9163, time 50.04ms, mfu 7.08%\n",
            "iter 340: loss 0.9104, time 50.27ms, mfu 7.11%\n",
            "iter 350: loss 0.9311, time 50.16ms, mfu 7.14%\n",
            "iter 360: loss 0.9050, time 50.51ms, mfu 7.16%\n",
            "iter 370: loss 0.9064, time 50.23ms, mfu 7.19%\n",
            "iter 380: loss 0.9168, time 50.28ms, mfu 7.21%\n",
            "iter 390: loss 0.8996, time 50.36ms, mfu 7.23%\n",
            "iter 400: loss 0.8992, time 50.22ms, mfu 7.25%\n",
            "iter 410: loss 0.8810, time 50.21ms, mfu 7.26%\n",
            "iter 420: loss 0.8911, time 50.05ms, mfu 7.28%\n",
            "iter 430: loss 0.8768, time 51.17ms, mfu 7.28%\n",
            "iter 440: loss 0.8749, time 50.88ms, mfu 7.28%\n",
            "iter 450: loss 0.8727, time 51.11ms, mfu 7.28%\n",
            "iter 460: loss 0.8571, time 50.99ms, mfu 7.28%\n",
            "iter 470: loss 0.8621, time 54.94ms, mfu 7.23%\n",
            "iter 480: loss 0.8545, time 51.04ms, mfu 7.24%\n",
            "iter 490: loss 0.8645, time 53.69ms, mfu 7.21%\n",
            "step 500: train loss 0.8094, val loss 0.8723\n",
            "saving checkpoint to out\n",
            "iter 500: loss 0.8430, time 6861.14ms, mfu 6.49%\n",
            "iter 510: loss 0.8324, time 50.33ms, mfu 6.58%\n",
            "iter 520: loss 0.8412, time 51.24ms, mfu 6.65%\n",
            "iter 530: loss 0.8302, time 50.31ms, mfu 6.72%\n",
            "iter 540: loss 0.8382, time 50.86ms, mfu 6.78%\n",
            "iter 550: loss 0.8318, time 50.19ms, mfu 6.85%\n",
            "iter 560: loss 0.8104, time 50.34ms, mfu 6.90%\n",
            "iter 570: loss 0.7978, time 50.48ms, mfu 6.95%\n",
            "iter 580: loss 0.7923, time 50.79ms, mfu 6.99%\n",
            "iter 590: loss 0.8014, time 50.27ms, mfu 7.03%\n",
            "iter 600: loss 0.7816, time 51.07ms, mfu 7.05%\n",
            "iter 610: loss 0.7810, time 50.91ms, mfu 7.08%\n",
            "iter 620: loss 0.7747, time 50.99ms, mfu 7.10%\n",
            "iter 630: loss 0.7772, time 50.91ms, mfu 7.12%\n",
            "iter 640: loss 0.7592, time 52.32ms, mfu 7.12%\n",
            "iter 650: loss 0.7657, time 50.74ms, mfu 7.14%\n",
            "iter 660: loss 0.7508, time 51.31ms, mfu 7.15%\n",
            "iter 670: loss 0.7452, time 51.25ms, mfu 7.16%\n",
            "iter 680: loss 0.7463, time 53.54ms, mfu 7.14%\n",
            "iter 690: loss 0.7252, time 53.22ms, mfu 7.13%\n",
            "iter 700: loss 0.7067, time 51.92ms, mfu 7.13%\n",
            "iter 710: loss 0.7037, time 50.53ms, mfu 7.15%\n",
            "iter 720: loss 0.6909, time 50.29ms, mfu 7.18%\n",
            "iter 730: loss 0.6845, time 50.22ms, mfu 7.20%\n",
            "iter 740: loss 0.6876, time 50.21ms, mfu 7.22%\n",
            "step 750: train loss 0.6250, val loss 0.6508\n",
            "saving checkpoint to out\n",
            "iter 750: loss 0.6745, time 6894.69ms, mfu 6.51%\n",
            "iter 760: loss 0.6803, time 50.33ms, mfu 6.59%\n",
            "iter 770: loss 0.6525, time 51.10ms, mfu 6.66%\n",
            "iter 780: loss 0.6594, time 51.18ms, mfu 6.72%\n",
            "iter 790: loss 0.6429, time 51.12ms, mfu 6.78%\n",
            "iter 800: loss 0.6351, time 50.98ms, mfu 6.83%\n",
            "iter 810: loss 0.6270, time 52.70ms, mfu 6.85%\n",
            "iter 820: loss 0.6267, time 50.99ms, mfu 6.90%\n",
            "iter 830: loss 0.6219, time 51.46ms, mfu 6.93%\n",
            "iter 840: loss 0.6004, time 52.22ms, mfu 6.95%\n",
            "iter 850: loss 0.6057, time 52.97ms, mfu 6.96%\n",
            "iter 860: loss 0.6024, time 52.93ms, mfu 6.96%\n",
            "iter 870: loss 0.5894, time 52.67ms, mfu 6.97%\n",
            "iter 880: loss 0.5815, time 50.14ms, mfu 7.02%\n",
            "iter 890: loss 0.5626, time 50.39ms, mfu 7.06%\n",
            "iter 900: loss 0.5629, time 50.30ms, mfu 7.09%\n",
            "iter 910: loss 0.5688, time 50.16ms, mfu 7.12%\n",
            "iter 920: loss 0.5667, time 50.19ms, mfu 7.15%\n",
            "iter 930: loss 0.5515, time 50.36ms, mfu 7.18%\n",
            "iter 940: loss 0.5456, time 50.16ms, mfu 7.20%\n",
            "iter 950: loss 0.5392, time 50.32ms, mfu 7.22%\n",
            "iter 960: loss 0.5446, time 50.24ms, mfu 7.24%\n",
            "iter 970: loss 0.5224, time 50.25ms, mfu 7.25%\n",
            "iter 980: loss 0.5290, time 50.33ms, mfu 7.27%\n",
            "iter 990: loss 0.5209, time 50.83ms, mfu 7.27%\n",
            "step 1000: train loss 0.4629, val loss 0.5628\n",
            "saving checkpoint to out\n",
            "iter 1000: loss 0.5150, time 7070.78ms, mfu 6.55%\n",
            "iter 1010: loss 0.5056, time 53.12ms, mfu 6.60%\n",
            "iter 1020: loss 0.5138, time 52.01ms, mfu 6.65%\n",
            "iter 1030: loss 0.4971, time 52.33ms, mfu 6.70%\n",
            "iter 1040: loss 0.4928, time 51.51ms, mfu 6.75%\n",
            "iter 1050: loss 0.4997, time 50.26ms, mfu 6.82%\n",
            "iter 1060: loss 0.4985, time 50.14ms, mfu 6.88%\n",
            "iter 1070: loss 0.4789, time 50.39ms, mfu 6.93%\n",
            "iter 1080: loss 0.4672, time 50.27ms, mfu 6.97%\n",
            "iter 1090: loss 0.4716, time 50.68ms, mfu 7.01%\n",
            "iter 1100: loss 0.4724, time 50.33ms, mfu 7.05%\n",
            "iter 1110: loss 0.4707, time 50.93ms, mfu 7.07%\n",
            "iter 1120: loss 0.4559, time 50.14ms, mfu 7.11%\n",
            "iter 1130: loss 0.4642, time 50.35ms, mfu 7.14%\n",
            "iter 1140: loss 0.4539, time 50.31ms, mfu 7.16%\n",
            "iter 1150: loss 0.4382, time 50.31ms, mfu 7.19%\n",
            "iter 1160: loss 0.4403, time 50.10ms, mfu 7.21%\n",
            "iter 1170: loss 0.4212, time 50.91ms, mfu 7.22%\n",
            "iter 1180: loss 0.4239, time 50.32ms, mfu 7.24%\n",
            "iter 1190: loss 0.4289, time 50.14ms, mfu 7.26%\n",
            "iter 1200: loss 0.4205, time 50.52ms, mfu 7.27%\n",
            "iter 1210: loss 0.4136, time 50.86ms, mfu 7.27%\n",
            "iter 1220: loss 0.3975, time 50.16ms, mfu 7.29%\n",
            "iter 1230: loss 0.4060, time 50.17ms, mfu 7.30%\n",
            "iter 1240: loss 0.4009, time 52.66ms, mfu 7.28%\n",
            "step 1250: train loss 0.3057, val loss 0.6846\n",
            "iter 1250: loss 0.3816, time 6891.29ms, mfu 6.55%\n",
            "iter 1260: loss 0.3975, time 50.23ms, mfu 6.64%\n",
            "iter 1270: loss 0.3835, time 50.32ms, mfu 6.71%\n",
            "iter 1280: loss 0.3660, time 50.42ms, mfu 6.78%\n",
            "iter 1290: loss 0.3695, time 50.71ms, mfu 6.84%\n",
            "iter 1300: loss 0.3755, time 50.26ms, mfu 6.89%\n",
            "iter 1310: loss 0.3504, time 50.31ms, mfu 6.94%\n",
            "iter 1320: loss 0.3502, time 50.40ms, mfu 6.99%\n",
            "iter 1330: loss 0.3471, time 51.27ms, mfu 7.01%\n",
            "iter 1340: loss 0.3379, time 51.61ms, mfu 7.03%\n",
            "iter 1350: loss 0.3473, time 50.26ms, mfu 7.07%\n",
            "iter 1360: loss 0.3442, time 51.20ms, mfu 7.09%\n",
            "iter 1370: loss 0.3260, time 50.30ms, mfu 7.12%\n",
            "iter 1380: loss 0.3161, time 51.16ms, mfu 7.14%\n",
            "iter 1390: loss 0.3152, time 50.29ms, mfu 7.16%\n",
            "iter 1400: loss 0.3071, time 50.19ms, mfu 7.19%\n",
            "iter 1410: loss 0.3149, time 51.74ms, mfu 7.19%\n",
            "iter 1420: loss 0.3044, time 53.41ms, mfu 7.17%\n",
            "iter 1430: loss 0.2997, time 51.11ms, mfu 7.18%\n",
            "iter 1440: loss 0.3000, time 50.74ms, mfu 7.19%\n",
            "iter 1450: loss 0.2975, time 51.41ms, mfu 7.20%\n",
            "iter 1460: loss 0.2902, time 51.23ms, mfu 7.20%\n",
            "iter 1470: loss 0.2761, time 52.13ms, mfu 7.20%\n",
            "iter 1480: loss 0.2776, time 51.70ms, mfu 7.20%\n",
            "iter 1490: loss 0.2762, time 54.48ms, mfu 7.16%\n",
            "step 1500: train loss 0.1817, val loss 0.9108\n",
            "iter 1500: loss 0.2715, time 6563.42ms, mfu 6.45%\n",
            "iter 1510: loss 0.2687, time 50.21ms, mfu 6.55%\n",
            "iter 1520: loss 0.2642, time 50.28ms, mfu 6.63%\n",
            "iter 1530: loss 0.2712, time 50.22ms, mfu 6.71%\n",
            "iter 1540: loss 0.2517, time 50.64ms, mfu 6.77%\n",
            "iter 1550: loss 0.2621, time 50.36ms, mfu 6.83%\n",
            "iter 1560: loss 0.2655, time 50.29ms, mfu 6.89%\n",
            "iter 1570: loss 0.2552, time 51.48ms, mfu 6.92%\n",
            "iter 1580: loss 0.2457, time 50.19ms, mfu 6.97%\n",
            "iter 1590: loss 0.2384, time 51.73ms, mfu 7.00%\n",
            "iter 1600: loss 0.2420, time 51.16ms, mfu 7.02%\n",
            "iter 1610: loss 0.2372, time 51.91ms, mfu 7.04%\n",
            "iter 1620: loss 0.2355, time 52.21ms, mfu 7.05%\n",
            "iter 1630: loss 0.2278, time 51.21ms, mfu 7.07%\n",
            "iter 1640: loss 0.2277, time 51.00ms, mfu 7.09%\n",
            "iter 1650: loss 0.2196, time 51.56ms, mfu 7.10%\n",
            "iter 1660: loss 0.2156, time 51.31ms, mfu 7.12%\n",
            "iter 1670: loss 0.2104, time 53.90ms, mfu 7.10%\n",
            "iter 1680: loss 0.2205, time 51.83ms, mfu 7.10%\n",
            "iter 1690: loss 0.2209, time 53.12ms, mfu 7.09%\n",
            "iter 1700: loss 0.2100, time 50.50ms, mfu 7.12%\n",
            "iter 1710: loss 0.1980, time 50.31ms, mfu 7.15%\n",
            "iter 1720: loss 0.2117, time 50.34ms, mfu 7.17%\n",
            "iter 1730: loss 0.2058, time 50.27ms, mfu 7.20%\n",
            "iter 1740: loss 0.2047, time 50.19ms, mfu 7.22%\n",
            "step 1750: train loss 0.1211, val loss 1.1288\n",
            "iter 1750: loss 0.2053, time 6475.91ms, mfu 6.50%\n",
            "iter 1760: loss 0.1917, time 50.63ms, mfu 6.59%\n",
            "iter 1770: loss 0.2051, time 51.26ms, mfu 6.65%\n",
            "iter 1780: loss 0.1972, time 54.28ms, mfu 6.67%\n",
            "iter 1790: loss 0.1945, time 50.84ms, mfu 6.74%\n",
            "iter 1800: loss 0.1949, time 52.22ms, mfu 6.78%\n",
            "iter 1810: loss 0.1817, time 52.49ms, mfu 6.81%\n",
            "iter 1820: loss 0.1826, time 51.70ms, mfu 6.85%\n",
            "iter 1830: loss 0.1793, time 51.40ms, mfu 6.89%\n",
            "iter 1840: loss 0.1867, time 52.50ms, mfu 6.91%\n",
            "iter 1850: loss 0.1792, time 53.00ms, mfu 6.92%\n",
            "iter 1860: loss 0.1804, time 52.15ms, mfu 6.94%\n",
            "iter 1870: loss 0.1822, time 53.70ms, mfu 6.94%\n",
            "iter 1880: loss 0.1733, time 50.74ms, mfu 6.98%\n",
            "iter 1890: loss 0.1650, time 50.42ms, mfu 7.02%\n",
            "iter 1900: loss 0.1607, time 50.17ms, mfu 7.06%\n",
            "iter 1910: loss 0.1707, time 51.38ms, mfu 7.08%\n",
            "iter 1920: loss 0.1702, time 50.35ms, mfu 7.11%\n",
            "iter 1930: loss 0.1705, time 50.22ms, mfu 7.14%\n",
            "iter 1940: loss 0.1675, time 51.84ms, mfu 7.14%\n",
            "iter 1950: loss 0.1599, time 50.83ms, mfu 7.16%\n",
            "iter 1960: loss 0.1660, time 51.29ms, mfu 7.17%\n",
            "iter 1970: loss 0.1675, time 50.27ms, mfu 7.19%\n",
            "iter 1980: loss 0.1696, time 50.49ms, mfu 7.21%\n",
            "iter 1990: loss 0.1583, time 52.81ms, mfu 7.19%\n",
            "step 2000: train loss 0.0916, val loss 1.2234\n",
            "iter 2000: loss 0.1537, time 6763.49ms, mfu 6.48%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd\n",
        "%cd nanoGPT_gpu\n",
        "!python3 sample.py --out_dir=\"out\" --dtype=\"float16\" --device=\"cuda\" | tail -n 12 | head -n 10 | tee csv_forecast.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFddIzXh2qE9",
        "outputId": "f35a43af-3e51-49c3-e572-f1e5d18d6b1e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "/root/nanoGPT_gpu\n",
            "8.08e+02b1.37e-01c5.93e-01a4.82e-01\n",
            "8.09e+02a5.36e-01c-3.87e-01b1.16e-01\n",
            "8.10e+02c5.88e-01a5.88e-01b1.50e-01\n",
            "8.11e+02b4.16e-01c3.55e-01a6.37e-01\n",
            "8.12e+02a6.85e-01b-6.34e-01c2.57e-01\n",
            "8.13e+02b1.37e-01c6.13e-01a7.29e-01\n",
            "8.14e+02a7.71e-01c6.77e-01b3.38e-01\n",
            "8.15e+02c8.92e-01b1.44e-01a8.09e-01\n",
            "8.16e+02b6.42e-01a8.44e-01c1.05e+00\n",
            "8.17e+02c1.21e+00a8.44e-01b2.34e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd\n",
        "%cd nanoGPT_gpu\n",
        "!cat csv_forecast.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhAGKel14ISw",
        "outputId": "7f510994-f8d8-4b1a-ca85-4f6a8f2b4492"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "/root/nanoGPT_gpu\n",
            "8.08e+02b1.37e-01c5.93e-01a4.82e-01\n",
            "8.09e+02a5.36e-01c-3.87e-01b1.16e-01\n",
            "8.10e+02c5.88e-01a5.88e-01b1.50e-01\n",
            "8.11e+02b4.16e-01c3.55e-01a6.37e-01\n",
            "8.12e+02a6.85e-01b-6.34e-01c2.57e-01\n",
            "8.13e+02b1.37e-01c6.13e-01a7.29e-01\n",
            "8.14e+02a7.71e-01c6.77e-01b3.38e-01\n",
            "8.15e+02c8.92e-01b1.44e-01a8.09e-01\n",
            "8.16e+02b6.42e-01a8.44e-01c1.05e+00\n",
            "8.17e+02c1.21e+00a8.44e-01b2.34e-01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd\n",
        "%cd nanoGPT_gpu\n",
        "!cp csv_forecast.txt ./data/csv_data\n",
        "%cd ./data/csv_data\n",
        "!python3 unprocess.py -i csv_forecast.txt -o csv_forecast.csv -l abc -c\n",
        "!cat csv_forecast.csv #todo comma fix after first term\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AjcHdmJK4l6l",
        "outputId": "f4a7d3ed-0ecd-4516-c467-cb05bb15a7d8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/root\n",
            "/root/nanoGPT_gpu\n",
            "/root/nanoGPT_gpu/data/csv_data\n",
            "8.08e+024.82e-01,1.37e-01,5.93e-01\n",
            "8.09e+025.36e-01,1.16e-01,-3.87e-01\n",
            "8.10e+025.88e-01,1.50e-01,5.88e-01\n",
            "8.11e+026.37e-01,4.16e-01,3.55e-01\n",
            "8.12e+026.85e-01,-6.34e-01,2.57e-01\n",
            "8.13e+027.29e-01,1.37e-01,6.13e-01\n",
            "8.14e+027.71e-01,3.38e-01,6.77e-01\n",
            "8.15e+028.09e-01,1.44e-01,8.92e-01\n",
            "8.16e+028.44e-01,6.42e-01,1.05e+00\n",
            "8.17e+028.44e-01,2.34e-01,1.21e+00\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}