{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/klei22/nanoGPT/blob/csv_process_flow/NanoGPT_Quickstart.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GJBs_flRovLc"
      },
      "source": [
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "## **CPU Quickstart**\n",
        "\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use this section for a CPU Quickstart for training from scratch plus inference."
      ],
      "metadata": {
        "id": "pn59dT_cokXS"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VM-6qXrqoknT"
      },
      "source": [
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "### **Install CPU Dependencies**\n",
        "\n",
        "</div>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gJr_9dXGpJ05",
        "outputId": "1eb072cd-14dd-45f1-aac5-a20b5dde01bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.2.1\n",
            "    Uninstalling networkx-3.2.1:\n",
            "      Successfully uninstalled networkx-3.2.1\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 2.1.3\n",
            "    Uninstalling MarkupSafe-2.1.3:\n",
            "      Successfully uninstalled MarkupSafe-2.1.3\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.6.0\n",
            "    Uninstalling fsspec-2023.6.0:\n",
            "      Successfully uninstalled fsspec-2023.6.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.13.1\n",
            "    Uninstalling filelock-3.13.1:\n",
            "      Successfully uninstalled filelock-3.13.1\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.3.2\n",
            "    Uninstalling charset-normalizer-3.3.2:\n",
            "      Successfully uninstalled charset-normalizer-3.3.2\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2023.7.22\n",
            "    Uninstalling certifi-2023.7.22:\n",
            "      Successfully uninstalled certifi-2023.7.22\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 1.4.0\n",
            "    Uninstalling absl-py-1.4.0:\n",
            "      Successfully uninstalled absl-py-1.4.0\n",
            "  Attempting uninstall: sentry-sdk\n",
            "    Found existing installation: sentry-sdk 1.37.1\n",
            "    Uninstalling sentry-sdk-1.37.1:\n",
            "      Successfully uninstalled sentry-sdk-1.37.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 9.0.0\n",
            "    Uninstalling pyarrow-9.0.0:\n",
            "      Successfully uninstalled pyarrow-9.0.0\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 1.5.3\n",
            "    Uninstalling pandas-1.5.3:\n",
            "      Successfully uninstalled pandas-1.5.3\n",
            "  Attempting uninstall: google-auth\n",
            "    Found existing installation: google-auth 2.17.3\n",
            "    Uninstalling google-auth-2.17.3:\n",
            "      Successfully uninstalled google-auth-2.17.3\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.16.0\n",
            "    Uninstalling wandb-0.16.0:\n",
            "      Successfully uninstalled wandb-0.16.0\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.15.0\n",
            "    Uninstalling tokenizers-0.15.0:\n",
            "      Successfully uninstalled tokenizers-0.15.0\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.0.0\n",
            "    Uninstalling google-auth-oauthlib-1.0.0:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.0.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.15.0\n",
            "    Uninstalling datasets-2.15.0:\n",
            "      Successfully uninstalled datasets-2.15.0\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.35.2\n",
            "    Uninstalling transformers-4.35.2:\n",
            "      Successfully uninstalled transformers-4.35.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.14.1\n",
            "    Uninstalling tensorboard-2.14.1:\n",
            "      Successfully uninstalled tensorboard-2.14.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "cupy-cuda11x 11.0.0 requires numpy<1.26,>=1.20, but you have numpy 1.26.1 which is incompatible.\n",
            "gcsfs 2023.6.0 requires fsspec==2023.6.0, but you have fsspec 2023.4.0 which is incompatible.\n",
            "google-colab 1.0.0 requires google-auth==2.17.3, but you have google-auth 2.23.4 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==1.5.3, but you have pandas 2.1.2 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.1 which is incompatible.\n",
            "ibis-framework 6.2.0 requires pyarrow<13,>=2, but you have pyarrow 14.0.0 which is incompatible.\n",
            "pandas-gbq 0.17.9 requires pyarrow<10.0dev,>=3.0.0, but you have pyarrow 14.0.0 which is incompatible.\n",
            "tensorflow 2.14.0 requires tensorboard<2.15,>=2.14, but you have tensorboard 2.15.1 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires absl-py<2.0.0,>=0.9, but you have absl-py 2.0.0 which is incompatible.\n",
            "tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.23.4 which is incompatible.\n",
            "yfinance 0.2.31 requires requests>=2.31, but you have requests 2.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-2.1.2 Pillow-9.3.0 absl-py-2.0.0 black-23.10.1 certifi-2022.12.7 charset-normalizer-2.1.1 datasets-2.14.6 filelock-3.9.0 fsspec-2023.4.0 google-auth-2.23.4 google-auth-oauthlib-1.1.0 huggingface-hub-0.17.3 mypy-extensions-1.0.0 networkx-3.0 numpy-1.26.1 pandas-2.1.2 pathspec-0.11.2 pathtools-0.1.2 platformdirs-3.11.0 protobuf-4.23.4 psutil-5.9.6 pyarrow-14.0.0 pynvim-0.4.3 regex-2023.10.3 requests-2.28.1 sentry-sdk-1.34.0 tensorboard-2.15.1 tokenizers-0.14.1 transformers-4.35.0 typing_extensions-4.4.0 tzdata-2023.3 urllib3-1.26.13 wandb-0.15.12\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "google",
                  "psutil"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "%cd\n",
        "!git clone https://github.com/ReaLLMASIC/nanoGPT.git nanoGPT_cpu\n",
        "%cd nanoGPT_cpu\n",
        "\n",
        "# check branch info\n",
        "!echo \"Cloned repository\"\n",
        "!git branch\n",
        "\n",
        "!ls\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cpu\n",
        "!pip install numpy transformers datasets tiktoken wandb tqdm tensorboard\n",
        "!pip install -r requirements_cpu.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fhs6GZ4qFMx"
      },
      "source": [
        "### **Run a Small Network on CPU**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gE-Ez1qtyIA",
        "outputId": "6eccf132-08fc-4938-e2a2-3d2f67c24cc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of dataset in characters: 1,115,394\n",
            "all the unique characters: \n",
            " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
            "vocab size: 65\n",
            "train has 1,003,854 tokens\n",
            "val has 111,540 tokens\n",
            "2023-11-25 17:59:31.800170: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2023-11-25 17:59:31.848450: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-25 17:59:31.848496: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-25 17:59:31.848542: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-25 17:59:31.857306: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-25 17:59:32.845127: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "{'block_size': 128, 'n_layer': 6, 'n_head': 6, 'n_embd': 126, 'dropout': 0.2, 'bias': False, 'use_post_ln': False, 'use_rmsnorm': True, 'use_rotary_embeddings': True, 'rope_variant': 'rope', 'shortrope_length': 16, 'use_abs_pos_embeddings': False, 'use_softmax_variant': False, 'softmax_variant': 'softermax', 'use_softermax_xmax': False, 'strongermax_strength': 2}\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "Use GELU\n",
            "number of parameters: 1.15M\n",
            "num decayed parameter tensors: 26, with 1,167,390 parameters\n",
            "num non-decayed parameter tensors: 13, with 1,638 parameters\n",
            "using fused AdamW: False\n",
            "step 0: train loss 4.3277, val loss 4.3219\n",
            "iter 0: loss 4.2949, time 37793.45ms, mfu -100.00%\n",
            "iter 150: loss 2.4864, time 367.59ms, mfu 0.06%\n",
            "step 300: train loss 2.3726, val loss 2.3858\n",
            "saving checkpoint to out\n",
            "iter 300: loss 2.3975, time 35052.33ms, mfu 0.05%\n",
            "iter 450: loss 2.3166, time 366.42ms, mfu 0.05%\n"
          ]
        }
      ],
      "source": [
        "!python3 data/shakespeare_char/prepare.py\n",
        "!python3 train.py --out_dir=out --device=cpu --eval_interval=300 --log_interval=150 --block_size=128 --batch_size=64 --n_layer=6 --n_head=6 --n_embd=126 --max_iters=2000 --lr_decay_iters=2 --dropout=0.2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdRyKR44dcNI"
      },
      "source": [
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "### **Run CPU Inference**\n",
        "\n",
        "</div>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4HZx7Gndbrh"
      },
      "outputs": [],
      "source": [
        "!python3 sample.py --device=cpu --out_dir=\"out\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<div class=\"mrkdown-google-sans\">\n",
        "\n",
        "# **GPU Quickstart**\n",
        "\n",
        "</div>"
      ],
      "metadata": {
        "id": "swIfEfkhpCSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd\n",
        "!git clone https://github.com/ReaLLMASIC/nanoGPT.git nanoGPT_gpu\n",
        "%cd nanoGPT_gpu\n",
        "\n",
        "# check branch info\n",
        "!echo \"Cloned repository\"\n",
        "!git branch\n",
        "\n",
        "!ls\n",
        "\n",
        "!pip install --upgrade pip\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install numpy transformers datasets tiktoken wandb tqdm tensorboard\n"
      ],
      "metadata": {
        "id": "z9TWJn8PpJLg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}