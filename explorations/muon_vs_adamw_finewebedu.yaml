# muon_vs_adamw_finewebedu.yaml
---
parameter_groups:
  - optimizer: ["adamw"]
    learning_rate: ["6e-4"]
    adamw_betas:
      - [0.9, 0.95]
    adamw_weight_decay: [0.1]
    adamw_eps: [1e-8]
  - optimizer: ["muon"]
    learning_rate: ["0.05"]
    muon_momentum: [0.95]

# GPT-2 architecture base hyperparameters
n_layer: [12]
n_head: [12]
n_embd: [768]
block_size: [1024]
batch_size: [32]
max_iters: [5000]
eval_interval: [500]
dataset: ["fineweb-edu"]
device: ["cuda"]
dtype: ["bfloat16"]
use_abs_pos_embeddings: [false]
use_rotary_embeddings: [true]
use_qk_norm: [true]
use_qk_norm_scale: [true]
use_peri_ln: [true, false]
softmax_variant_attn: ["softmax"]
compile: [true]
tensorboard_run_name: ["muon_vs_adamw_finewebedu"]
