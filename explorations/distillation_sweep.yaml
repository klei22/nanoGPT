# explorations/distillation_sweep.yaml
---
# Knowledge distillation sweep covering every implemented loss variant.
# Provide the teacher checkpoint path via the DISTILLATION_TEACHER_CKPT environment
# variable before launching `run_exploration_monitor.py` or similar tooling, e.g.
#   DISTILLATION_TEACHER_CKPT=out/teacher/ckpt.pt ./run_exploration_monitor.py ...
# Each parameter group below pairs a loss variant with a representative spread of
# temperatures, weights, and epsilons (where applicable).

# Base hyperparameters shared across the sweep.
max_iters: [800]
eval_interval: [200]
eval_iters: [200]
log_interval: [10]
block_size: [512]
batch_size: [32]
learning_rate: [3.0e-4]
min_lr: [3.0e-5]
warmup_iters: [200]
n_layer: [6]
n_head: [6]
n_embd: [384]
compile: [true]
device: ["cuda"]
dtype: ["bfloat16"]
dataset: ["minipile"]
# Teacher checkpoint injected at runtime.
distillation_teacher_ckpt: ["${DISTILLATION_TEACHER_CKPT}"]

parameter_groups:
  # Forward KL: classic teacher -> student distillation.
  - distillation_loss: ["kl_divergence"]
    distillation_temperature: [1.0, 2.0, 4.0]
    distillation_weight: [0.2, 0.5, 1.0]
    distillation_eps: [1.0e-8]

  # Reverse KL emphasises student coverage of teacher modes.
  - distillation_loss: ["reverse_kl"]
    distillation_temperature: [0.5, 1.0, 2.0]
    distillation_weight: [0.3, 0.5, 0.7]
    distillation_eps: [1.0e-8, 1.0e-6]

  # Symmetric KL balances forward and reverse directions.
  - distillation_loss: ["symmetric_kl"]
    distillation_temperature: [1.0, 2.0]
    distillation_weight: [0.3, 0.6, 1.0]
    distillation_eps: [1.0e-8, 1.0e-6]

  # Jensen-Shannon divergence with mixture regularisation.
  - distillation_loss: ["jensen_shannon"]
    distillation_temperature: [1.0, 2.0]
    distillation_weight: [0.3, 0.6, 1.0]
    distillation_eps: [1.0e-8, 1.0e-6]

  # Temperature-scaled logit mean squared error.
  - distillation_loss: ["logit_mse"]
    distillation_temperature: [0.7, 1.0, 2.0]
    distillation_weight: [0.3, 0.5, 0.7]
    distillation_eps: [1.0e-8]
